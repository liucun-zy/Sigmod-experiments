#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–çš„OCRå¤„ç†æ¨¡å—
ä½¿ç”¨PaddleOCRæ›¿æ¢Tesseractï¼Œæ”¯æŒCUDAã€ç¹ä½“ä¸­æ–‡å’Œè‹±æ–‡
"""

import os
import sys
import re
import logging
import fitz  # PyMuPDF
from PIL import Image
import io
import numpy as np
from pathlib import Path
from typing import List, Tuple, Optional, Dict, Any
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class OptimizedOCR:
    """ä¼˜åŒ–çš„OCRå¤„ç†å™¨"""
    
    def __init__(self, use_gpu: bool = True, lang: str = 'ch'):
        """
        åˆå§‹åŒ–OCRå¤„ç†å™¨
        
        Args:
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            lang: è¯­è¨€è®¾ç½® ('ch' for Chinese, 'en' for English, 'ch' for both)
        """
        self.use_gpu = use_gpu
        self.lang = lang
        self.ocr = None
        self._init_ocr()
    
    def _init_ocr(self):
        """åˆå§‹åŒ–PaddleOCR"""
        try:
            from paddleocr import PaddleOCR
            
            # æ£€æµ‹GPUå¯ç”¨æ€§
            if self.use_gpu:
                try:
                    import torch
                    if torch.cuda.is_available():
                        logger.info("âœ… æ£€æµ‹åˆ°CUDA GPUï¼Œå¯ç”¨GPUåŠ é€Ÿ")
                        use_gpu = True
                    else:
                        logger.warning("âŒ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                        use_gpu = False
                except ImportError:
                    logger.warning("âŒ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼")
                    use_gpu = False
            else:
                use_gpu = False
            
            # åˆå§‹åŒ–PaddleOCR - æ”¯æŒä¸­æ–‡ç¹ä½“å’Œè‹±æ–‡
            self.ocr = PaddleOCR(
                use_textline_orientation=True,
                lang='ch'  # ä¸­æ–‡ï¼ˆåŒ…å«ç¹ä½“ï¼‰
            )
            logger.info(f"âœ… PaddleOCRåˆå§‹åŒ–æˆåŠŸ (GPU: {use_gpu})")
            
        except ImportError:
            logger.error("âŒ PaddleOCRæœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install paddlepaddle paddleocr")
            raise
        except Exception as e:
            logger.error(f"âŒ PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def extract_text_from_page(self, doc: fitz.Document, page_num: int) -> str:
        """ä»PDFé¡µé¢æå–æ–‡æœ¬å±‚"""
        try:
            page = doc.load_page(page_num)
            text = page.get_text()
            return text.strip()
        except Exception as e:
            logger.error(f"æå–ç¬¬{page_num + 1}é¡µæ–‡æœ¬å¤±è´¥: {e}")
            return ""
    
    def ocr_page_image(self, page: fitz.Page, dpi: int = 300) -> str:
        """å¯¹PDFé¡µé¢è¿›è¡ŒOCRè¯†åˆ«"""
        try:
            # å°†é¡µé¢æ¸²æŸ“ä¸ºé«˜åˆ†è¾¨ç‡å›¾åƒ
            mat = fitz.Matrix(dpi/72, dpi/72)  # 72æ˜¯PDFçš„é»˜è®¤DPI
            pix = page.get_pixmap(matrix=mat)
            img_data = pix.tobytes("png")
            
            # ä½¿ç”¨PaddleOCRè¯†åˆ«
            result = self.ocr.ocr(img_data)
            
            if not result or not result[0]:
                return ""
            
            # æå–è¯†åˆ«çš„æ–‡æœ¬
            text_lines = []
            for line in result[0]:
                if line and len(line) >= 2:
                    text_lines.append(line[1][0])
            
            return "\n".join(text_lines)
            
        except Exception as e:
            logger.error(f"OCRè¯†åˆ«å¤±è´¥: {e}")
            return ""

class TOCDetector:
    """ç›®å½•é¡µæ£€æµ‹å™¨"""
    
    def __init__(self):
        # ç›®å½•å…³é”®è¯ï¼ˆæ”¯æŒç¹ä½“å’Œè‹±æ–‡ï¼‰
        self.toc_keywords = {
            'chinese': [
                'ç›®å½•', 'ç›®éŒ„', 'ç›®æ¬¡', 'ç´¢å¼•', 'ç« èŠ‚ç›®å½•', 'ç« ç¯€ç›®éŒ„',
                'table of contents', 'contents', 'index'
            ],
            'english': [
                'table of contents', 'contents', 'index', 'toc',
                'chapter', 'section', 'part', 'appendix', 'references',
                'bibliography', 'glossary'
            ]
        }
        
        # ç›®å½•é¡¹æ¨¡å¼
        self.item_patterns = [
            r'^\s*\d+\.\s+[^\n]+',  # 1. æ ‡é¢˜
            r'^\s*\d+\.\d+\.\s+[^\n]+',  # 1.1. æ ‡é¢˜
            r'^\s*[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ã€.]\s+[^\n]+',  # ä¸€ã€ äºŒã€
            r'^\s*[ï¼ˆ(][ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+[ï¼‰)]\s+[^\n]+',  # (ä¸€) (äºŒ)
            r'^\s*[A-Z][\.\)]\s+[^\n]+',  # A. B. A) B)
            r'^\s*[â—â—â– â—†â€¢Â·â—‹]\s+[^\n]+',  # ç‰¹æ®Šç¬¦å·
        ]
        
        # é¡µç æ¨¡å¼
        self.page_patterns = [
            r'\.{3,}\s*\d+$',  # ... æ•°å­—
            r'\.{3,}\d+$',     # ...æ•°å­—
            r'\.{2,}\s*\d+$',  # .. æ•°å­—
            r'\.{2,}\d+$',     # ..æ•°å­—
        ]
    
    def is_toc_page(self, text: str) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦ä¸ºç›®å½•é¡µ
        
        Args:
            text: é¡µé¢æ–‡æœ¬å†…å®¹
            
        Returns:
            æ˜¯å¦ä¸ºç›®å½•é¡µ
        """
        if not text:
            return False
        
        # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        text_lower = text.lower()
        
        # 1. æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®å½•å…³é”®è¯
        for keyword in self.toc_keywords['chinese'] + self.toc_keywords['english']:
            if keyword in text_lower:
                return True
        
        # 2. å¢å¼ºçš„ç›®å½•é¡µæ£€æµ‹
        return self._enhanced_toc_detection(text)
    
    def _enhanced_toc_detection(self, text: str) -> bool:
        """å¢å¼ºçš„ç›®å½•é¡µæ£€æµ‹é€»è¾‘"""
        if not text:
            return False
        
        lines = text.split('\n')
        toc_indicators = 0
        lines_with_content = 0
        
        # æ£€æŸ¥æ¯è¡Œæ˜¯å¦åŒ…å«ç›®å½•ç‰¹å¾
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            lines_with_content += 1
            
            # æ£€æŸ¥ç« èŠ‚ç¼–å·æ¨¡å¼
            if re.search(r'^\d+\.?\s+[A-Za-z\u4e00-\u9fff]', line):
                toc_indicators += 2
            
            # æ£€æŸ¥é¡µç æ¨¡å¼
            if re.search(r'\.{3,}\s*\d+\s*$', line):
                toc_indicators += 2
            
            # æ£€æŸ¥çœç•¥å·
            if re.search(r'\.{3,}|â€¦{3,}', line):
                toc_indicators += 1
            
            # æ£€æŸ¥ç« èŠ‚å…³é”®è¯
            chapter_keywords = ['chapter', 'section', 'part', 'appendix', 'references',
                              'ç« ', 'ç¯€', 'éƒ¨', 'ç¯‡', 'ç¼–', 'ç·¨', 'é™„å½•', 'é™„éŒ„', 'å‚è€ƒæ–‡çŒ®']
            if any(keyword in line.lower() for keyword in chapter_keywords):
                toc_indicators += 1
            
            # æ£€æŸ¥æ•°å­—-æ•°å­—æ¨¡å¼
            if re.search(r'\d+[\.-]\d+', line):
                toc_indicators += 1
            
            # æ£€æŸ¥ç›®å½•é¡µç‰¹æœ‰æ ¼å¼
            if re.search(r'^\d+\s+[A-Za-z\u4e00-\u9fff].*\s+\d+$', line):
                toc_indicators += 2
        
        # æ’é™¤éç›®å½•å†…å®¹
        non_toc_keywords = ['å­£åº¦', 'å¹´åº¦', 'æŠ¥å‘Š', 'å ±å‘Š', 'quarter', 'annual', 'report', 
                           'ä¸šç»©', 'æ¥­ç¸¾', 'è¡¨ç°', 'è¡¨ç¾', 'è‰¯å¥½', 'ä¸‹æ»‘', 'æ¢å¤']
        if any(keyword in text.lower() for keyword in non_toc_keywords):
            return False
        
        # åˆ¤æ–­æ¡ä»¶
        if lines_with_content == 0:
            return False
        
        toc_density = toc_indicators / lines_with_content
        
        # éœ€è¦æ›´é«˜çš„å¯†åº¦å’Œæ›´å¤šçš„ç‰¹å¾
        if toc_density > 0.5 and toc_indicators >= 5:
            return True
        
        # æˆ–è€…æœ‰å¾ˆå¼ºçš„ç›®å½•ç‰¹å¾
        if toc_indicators >= 8:
            return True
        
        return False

class PDFProcessor:
    """PDFå¤„ç†å™¨"""
    
    def __init__(self, use_gpu: bool = True, max_pages: int = 5):
        """
        åˆå§‹åŒ–PDFå¤„ç†å™¨
        
        Args:
            use_gpu: æ˜¯å¦ä½¿ç”¨GPU
            max_pages: æœ€å¤§æ£€æŸ¥é¡µæ•°ï¼ˆé»˜è®¤5é¡µï¼‰
        """
        self.ocr = OptimizedOCR(use_gpu=use_gpu)
        self.toc_detector = TOCDetector()
        self.max_pages = max_pages
    
    def find_toc_pages(self, pdf_path: str) -> List[int]:
        """
        æŸ¥æ‰¾ç›®å½•é¡µï¼ˆåªæŸ¥æ‰¾ç¬¬ä¸€ä¸ªç›®å½•é¡µï¼‰
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            ç›®å½•é¡µé¡µç åˆ—è¡¨ï¼ˆä»0å¼€å§‹ï¼ŒåªåŒ…å«ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„ç›®å½•é¡µï¼‰
        """
        try:
            doc = fitz.open(pdf_path)
            total_pages = len(doc)
            check_pages = min(self.max_pages, total_pages)
            
            logger.info(f"å¼€å§‹æ£€æŸ¥PDFå‰{check_pages}é¡µ...")
            
            for page_num in range(check_pages):
                logger.info(f"æ£€æŸ¥ç¬¬{page_num + 1}é¡µ...")
                
                # 1. é¦–å…ˆå°è¯•æ–‡å­—å±‚åŒ¹é…
                text = self.ocr.extract_text_from_page(doc, page_num)
                if text:
                    logger.debug(f"ç¬¬{page_num + 1}é¡µæ–‡æœ¬é¢„è§ˆ: {text[:200]}...")
                
                if self.toc_detector.is_toc_page(text):
                    logger.info(f"é€šè¿‡æ–‡å­—å±‚åŒ¹é…æ‰¾åˆ°ç›®å½•é¡µ: ç¬¬{page_num + 1}é¡µ")
                    doc.close()
                    return [page_num]  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç›®å½•é¡µå°±è¿”å›
                
                # 2. å¦‚æœæ–‡å­—å±‚åŒ¹é…å¤±è´¥ï¼Œå°è¯•OCR
                page = doc.load_page(page_num)
                ocr_text = self.ocr.ocr_page_image(page)
                
                if ocr_text and self.toc_detector.is_toc_page(ocr_text):
                    logger.info(f"é€šè¿‡OCRåŒ¹é…æ‰¾åˆ°ç›®å½•é¡µ: ç¬¬{page_num + 1}é¡µ")
                    doc.close()
                    return [page_num]  # æ‰¾åˆ°ç¬¬ä¸€ä¸ªç›®å½•é¡µå°±è¿”å›
            
            doc.close()
            logger.warning(f"åœ¨å‰{check_pages}é¡µä¸­æœªæ‰¾åˆ°ç›®å½•é¡µ")
            return []
            
        except Exception as e:
            logger.error(f"æŸ¥æ‰¾ç›®å½•é¡µå¤±è´¥: {e}")
            return []
    
    def extract_toc_images(self, pdf_path: str, toc_pages: List[int], output_dir: str) -> List[str]:
        """
        æå–ç›®å½•é¡µå›¾åƒ
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            toc_pages: ç›®å½•é¡µé¡µç åˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            æå–çš„å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
        """
        try:
            os.makedirs(output_dir, exist_ok=True)
            doc = fitz.open(pdf_path)
            
            image_paths = []
            
            for page_num in toc_pages:
                page = doc.load_page(page_num)
                
                # é«˜åˆ†è¾¨ç‡æ¸²æŸ“
                mat = fitz.Matrix(3.0, 3.0)  # 3å€ç¼©æ”¾
                pix = page.get_pixmap(matrix=mat)
                
                # ä¿å­˜ä¸ºJPG
                image_path = os.path.join(output_dir, f"toc_page_{page_num + 1}.jpg")
                pix.save(image_path)
                
                image_paths.append(image_path)
                logger.info(f"å·²æå–ç›®å½•é¡µå›¾åƒ: {image_path}")
            
            doc.close()
            return image_paths
            
        except Exception as e:
            logger.error(f"æå–ç›®å½•é¡µå›¾åƒå¤±è´¥: {e}")
            return []
    
    def remove_toc_pages(self, pdf_path: str, toc_pages: List[int], output_path: str) -> bool:
        """
        ä»PDFä¸­åˆ é™¤ç›®å½•é¡µ
        
        Args:
            pdf_path: åŸPDFæ–‡ä»¶è·¯å¾„
            toc_pages: ç›®å½•é¡µé¡µç åˆ—è¡¨
            output_path: è¾“å‡ºPDFè·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸ
        """
        try:
            doc = fitz.open(pdf_path)
            
            # åˆ é™¤æŒ‡å®šé¡µé¢
            for page_num in reversed(toc_pages):  # ä»åå¾€å‰åˆ é™¤
                doc.delete_page(page_num)
            
            # ä¿å­˜æ–°PDF
            doc.save(output_path)
            doc.close()
            
            logger.info(f"å·²ç”Ÿæˆå»ç›®å½•PDF: {output_path}")
            return True
            
        except Exception as e:
            logger.error(f"åˆ é™¤ç›®å½•é¡µå¤±è´¥: {e}")
            return False
    
    def process_pdf(self, pdf_path: str, output_dir: str) -> Dict[str, Any]:
        """
        å¤„ç†å•ä¸ªPDFæ–‡ä»¶
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            
        Returns:
            å¤„ç†ç»“æœå­—å…¸
        """
        result = {
            'success': False,
            'toc_pages': [],
            'image_paths': [],
            'output_pdf': '',
            'error': ''
        }
        
        try:
            # 1. æŸ¥æ‰¾ç›®å½•é¡µ
            toc_pages = self.find_toc_pages(pdf_path)
            
            if not toc_pages:
                result['error'] = 'æœªæ‰¾åˆ°ç›®å½•é¡µ'
                return result
            
            # 2. æå–ç›®å½•é¡µå›¾åƒ
            image_paths = self.extract_toc_images(pdf_path, toc_pages, output_dir)
            
            # 3. åˆ é™¤ç›®å½•é¡µå¹¶ä¿å­˜æ–°PDF
            pdf_name = Path(pdf_path).stem
            output_pdf = os.path.join(output_dir, f"{pdf_name}_no_toc.pdf")
            
            if self.remove_toc_pages(pdf_path, toc_pages, output_pdf):
                result['success'] = True
                result['toc_pages'] = toc_pages
                result['image_paths'] = image_paths
                result['output_pdf'] = output_pdf
            else:
                result['error'] = 'åˆ é™¤ç›®å½•é¡µå¤±è´¥'
            
        except Exception as e:
            result['error'] = str(e)
            logger.error(f"å¤„ç†PDFå¤±è´¥: {e}")
        
        return result

def main():
    """ä¸»å‡½æ•° - ç¡¬ç¼–ç å¾ªç¯å¤„ç†"""
    # ç¡¬ç¼–ç è·¯å¾„é…ç½®
    input_dir = r"/Users/liucun/Desktop/ç›®å½•é¡µæå–ä»£ç /USESG/downloaded_pdfs"  # è¾“å…¥PDFç›®å½•
    output_base_dir = r"/Users/liucun/Desktop/ç›®å½•é¡µæå–ä»£ç /processed_pdfs"   # è¾“å‡ºåŸºç¡€ç›®å½•
    
    # æ£€æŸ¥è¾“å…¥ç›®å½•æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_dir):
        logger.error(f"è¾“å…¥ç›®å½•ä¸å­˜åœ¨: {input_dir}")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    success_dir = os.path.join(output_base_dir, "success")
    failed_dir = os.path.join(output_base_dir, "failed")
    os.makedirs(success_dir, exist_ok=True)
    os.makedirs(failed_dir, exist_ok=True)
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = PDFProcessor(use_gpu=False, max_pages=5)  # ä½¿ç”¨CPUæ¨¡å¼ï¼Œåªæ£€æŸ¥å‰5é¡µ
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_files = 0
    success_count = 0
    failed_count = 0
    failed_files = []
    
    # è·å–æ‰€æœ‰PDFæ–‡ä»¶
    pdf_files = [f for f in os.listdir(input_dir) if f.lower().endswith('.pdf')]
    
    if not pdf_files:
        logger.warning(f"åœ¨ç›®å½• {input_dir} ä¸­æœªæ‰¾åˆ°PDFæ–‡ä»¶")
        return
    
    logger.info(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶ï¼Œå¼€å§‹å¤„ç†...")
    
    # å¾ªç¯å¤„ç†æ¯ä¸ªPDFæ–‡ä»¶
    for i, pdf_filename in enumerate(pdf_files, 1):
        pdf_path = os.path.join(input_dir, pdf_filename)
        logger.info(f"\nå¤„ç†è¿›åº¦: {i}/{len(pdf_files)} - {pdf_filename}")
        
        total_files += 1
        
        try:
            # ä¸ºæ¯ä¸ªPDFåˆ›å»ºç‹¬ç«‹çš„å­æ–‡ä»¶å¤¹
            pdf_name = Path(pdf_filename).stem
            pdf_output_dir = os.path.join(success_dir, pdf_name)
            os.makedirs(pdf_output_dir, exist_ok=True)
            
            # å¤„ç†PDF
            result = processor.process_pdf(pdf_path, pdf_output_dir)
            
            if result['success']:
                success_count += 1
                logger.info(f"âœ… æˆåŠŸå¤„ç†: {pdf_filename}")
                logger.info(f"   ç›®å½•é¡µ: {[p+1 for p in result['toc_pages']]}")
                logger.info(f"   è¾“å‡ºç›®å½•: {pdf_output_dir}")
            else:
                failed_count += 1
                failed_files.append(pdf_filename)
                logger.warning(f"âŒ å¤„ç†å¤±è´¥: {pdf_filename} - {result['error']}")
                
                # å¤åˆ¶å¤±è´¥çš„æ–‡ä»¶åˆ°failedç›®å½•
                failed_pdf_dir = os.path.join(failed_dir, pdf_name)
                os.makedirs(failed_pdf_dir, exist_ok=True)
                import shutil
                shutil.copy2(pdf_path, os.path.join(failed_pdf_dir, pdf_filename))
                
        except Exception as e:
            failed_count += 1
            failed_files.append(pdf_filename)
            logger.error(f"âŒ å¤„ç†å¼‚å¸¸: {pdf_filename} - {e}")
            
            # å¤åˆ¶å¼‚å¸¸çš„æ–‡ä»¶åˆ°failedç›®å½•
            pdf_name = Path(pdf_filename).stem
            failed_pdf_dir = os.path.join(failed_dir, pdf_name)
            os.makedirs(failed_pdf_dir, exist_ok=True)
            import shutil
            shutil.copy2(pdf_path, os.path.join(failed_pdf_dir, pdf_filename))
    
    # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
    report_file = os.path.join(output_base_dir, "processing_report.txt")
    try:
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("PDFç›®å½•é¡µæå–å¤„ç†æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n")
            f.write(f"å¤„ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è¾“å…¥ç›®å½•: {input_dir}\n")
            f.write(f"è¾“å‡ºç›®å½•: {output_base_dir}\n")
            f.write(f"æ€»æ–‡ä»¶æ•°: {total_files}\n")
            f.write(f"æˆåŠŸå¤„ç†: {success_count}\n")
            f.write(f"å¤„ç†å¤±è´¥: {failed_count}\n")
            f.write(f"æˆåŠŸç‡: {success_count/total_files*100:.1f}%\n\n")
            
            if failed_files:
                f.write("å¤±è´¥çš„æ–‡ä»¶åˆ—è¡¨:\n")
                f.write("-" * 30 + "\n")
                for file in failed_files:
                    f.write(f"- {file}\n")
            
            f.write(f"\nè¾“å‡ºç›®å½•ç»“æ„:\n")
            f.write(f"- {success_dir}/ - æˆåŠŸå¤„ç†çš„æ–‡ä»¶ï¼ˆæ¯ä¸ªPDFä¸€ä¸ªå­æ–‡ä»¶å¤¹ï¼‰\n")
            f.write(f"- {failed_dir}/ - å¤„ç†å¤±è´¥çš„åŸPDFæ–‡ä»¶\n")
            f.write(f"- {report_file} - æœ¬æŠ¥å‘Š\n")
        
        logger.info(f"ğŸ“Š å¤„ç†æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
        
    except Exception as e:
        logger.error(f"ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")
    
    # æ‰“å°æœ€ç»ˆç»Ÿè®¡
    print("\n" + "="*50)
    print("å¤„ç†å®Œæˆï¼")
    print("="*50)
    print(f"æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"æˆåŠŸå¤„ç†: {success_count}")
    print(f"å¤„ç†å¤±è´¥: {failed_count}")
    print(f"æˆåŠŸç‡: {success_count/total_files*100:.1f}%")
    
    print(f"\nè¾“å‡ºç›®å½•ç»“æ„:")
    print(f"âœ… æˆåŠŸæ–‡ä»¶: {success_dir}/")
    print(f"âŒ å¤±è´¥æ–‡ä»¶: {failed_dir}/")
    print(f"ğŸ“Š å¤„ç†æŠ¥å‘Š: {report_file}")
    
    if failed_files:
        print(f"\nå¤±è´¥çš„æ–‡ä»¶:")
        for file in failed_files:
            print(f"  - {file}")
    
    print("="*50)

if __name__ == "__main__":
    main() 