# -*- coding: utf-8 -*-

"""
Markdownæ ‡é¢˜å¯¹é½ä¸æ ¼å¼åŒ–å·¥å…·

åŠŸèƒ½æè¿°ï¼š
    å°†Markdownæ–‡ä»¶ä¸­çš„æ ‡é¢˜ç»“æ„ä¸PDFç›®å½•ç»“æ„è¿›è¡Œå¯¹é½ï¼Œç¡®ä¿æ ‡é¢˜çš„å®Œæ•´æ€§å’Œæ­£ç¡®æ€§ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. æ ‡é¢˜å¯¹é½
   - ç¡®ä¿æ‰€æœ‰åœ¨PDFç›®å½•ä¸­å®šä¹‰çš„æ ‡é¢˜éƒ½å­˜åœ¨äºMarkdownæ–‡ä»¶ä¸­
   - æŒ‰ç…§PDFç›®å½•çš„é¡ºåºæ’åˆ—æ ‡é¢˜
   - è‡ªåŠ¨è¡¥å……ç¼ºå¤±çš„ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜

2. æ ‡é¢˜æ ¼å¼åŒ–
   - ä¸»æ ‡é¢˜ç»Ÿä¸€æ ¼å¼åŒ–ä¸º "# Title"
   - å­æ ‡é¢˜ç»Ÿä¸€æ ¼å¼åŒ–ä¸º "## Subtitle"
   - æœªå¯¹é½çš„æ ‡é¢˜è½¬æ¢ä¸º "### Subtitle"

3. æ ‡é¢˜åŒ¹é…
   - æ”¯æŒæ ‡é¢˜æ–‡æœ¬çš„æ¨¡ç³ŠåŒ¹é…ï¼ˆå¿½ç•¥ç©ºæ ¼å·®å¼‚ï¼‰
   - ä¿æŒæ ‡é¢˜çš„åŸå§‹æ ¼å¼å’Œå¤§å°å†™

è¾“å…¥æ–‡ä»¶ï¼š
    - pdf_titles.json: PDFç›®å½•ç»“æ„æ–‡ä»¶
    - markdown2_cleaned.md: å¾…å¤„ç†çš„Markdownæ–‡ä»¶

è¾“å‡ºæ–‡ä»¶ï¼š
    - markdown_aligned.md: å¤„ç†åçš„Markdownæ–‡ä»¶

æ³¨æ„äº‹é¡¹ï¼š
    - ä¿æŒæ–‡æ¡£éæ ‡é¢˜å†…å®¹ä¸å˜
    - ä¿æŒæ ‡é¢˜çš„å±‚çº§ç»“æ„
    - ç¡®ä¿æ ‡é¢˜æ’å…¥ä½ç½®çš„åˆç†æ€§
"""

import json
import re
import os
from rapidfuzz import fuzz, process as rapidfuzz_process
from typing import List, Dict, Tuple, Set
from .deepseek_title import deepseek_api, SYSTEM_PROMPT_SELECT_TITLE, SYSTEM_PROMPT_INSERT_POSITION
from pathlib import Path

def extract_chinese(text: str) -> str:
    """æå–æ–‡æœ¬ä¸­çš„ä¸­æ–‡å­—ç¬¦"""
    return ''.join(char for char in text if '\u4e00' <= char <= '\u9fff')

def normalize_title(title: str) -> str:
    """æ ‡å‡†åŒ–æ ‡é¢˜æ–‡æœ¬ï¼Œåªä¿ç•™ä¸­æ–‡å­—ç¬¦å¹¶ç§»é™¤ç©ºç™½"""
    # åªæå–ä¸­æ–‡å­—ç¬¦
    chinese_only = extract_chinese(title)
    # ç§»é™¤æ‰€æœ‰ç©ºç™½å­—ç¬¦
    return re.sub(r'\s+', '', chinese_only)

def get_title_level(entry: dict, is_top_level: bool = False, parent_level: int = 0, is_in_third_level: bool = False) -> Tuple[int, str]:
    """æ ¹æ®JSONç»“æ„ç¡®å®šæ ‡é¢˜å±‚çº§å’Œçˆ¶æ ‡é¢˜
    Args:
        entry: JSONæ ‡é¢˜æ¡ç›®
        is_top_level: æ˜¯å¦æ˜¯é¡¶çº§æ ‡é¢˜ï¼ˆJSONæ•°ç»„ä¸­çš„ç›´æ¥å…ƒç´ ï¼‰
        parent_level: çˆ¶æ ‡é¢˜çš„å±‚çº§
        is_in_third_level: æ˜¯å¦åœ¨ç¬¬ä¸‰å±‚subtitlesä¸­
    Returns:
        Tuple[int, str]: (å±‚çº§, çˆ¶æ ‡é¢˜)
        
    è§„åˆ™ï¼š
    1. é¡¶çº§æ ‡é¢˜ï¼ˆJSONæ•°ç»„ä¸­çš„ç›´æ¥å…ƒç´ ï¼‰ä¸ºä¸€çº§æ ‡é¢˜ (#)
    2. äºŒçº§åµŒå¥—ï¼š
       - åœ¨subtitlesä¸­çš„titleä¸ºäºŒçº§æ ‡é¢˜ (##)
    3. ä¸‰çº§åµŒå¥—ï¼š
       - åœ¨subtitlesçš„subtitlesä¸­çš„å­—ç¬¦ä¸²ä¸ºä¸‰çº§æ ‡é¢˜ (###)
    4. å››çº§æ ‡é¢˜ï¼š
       - ä¸‰çº§æ ‡é¢˜ä¸‹çš„æ ‡é¢˜ä¸ºå››çº§æ ‡é¢˜ (####)
    """
    # å¦‚æœæ˜¯åœ¨ç¬¬ä¸‰å±‚subtitlesä¸­çš„æ ‡é¢˜ï¼Œç›´æ¥è¿”å›ä¸‰çº§æ ‡é¢˜
    if is_in_third_level:
        return (3, None)
        
    if not isinstance(entry, dict):
        # å­—ç¬¦ä¸²ç±»å‹çš„æ ‡é¢˜
        if parent_level == 1:
            return (3, None)  # ä¸€çº§æ ‡é¢˜ä¸‹çš„å­—ç¬¦ä¸²ä¸ºä¸‰çº§æ ‡é¢˜
        elif parent_level == 2:
            return (3, None)  # äºŒçº§æ ‡é¢˜ä¸‹çš„å­—ç¬¦ä¸²ä¸ºä¸‰çº§æ ‡é¢˜
        elif parent_level == 3:
            return (4, None)  # ä¸‰çº§æ ‡é¢˜ä¸‹çš„å­—ç¬¦ä¸²ä¸ºå››çº§æ ‡é¢˜
        return (4, None)  # å…¶ä»–æƒ…å†µä¸ºå››çº§æ ‡é¢˜
        
    title = entry.get('title', '')
    if not title:
        return (1, None)
        
    # é¡¶çº§æ ‡é¢˜ï¼ˆJSONæ•°ç»„ä¸­çš„ç›´æ¥å…ƒç´ ï¼‰å§‹ç»ˆä¸ºä¸€çº§æ ‡é¢˜
    if is_top_level:
        return (1, None)
        
    # æ ¹æ®çˆ¶å±‚çº§å’Œsubtitlesç»“æ„åˆ¤æ–­
    if 'subtitles' in entry:
        # æ£€æŸ¥subtitlesçš„ç¬¬ä¸€ä¸ªå…ƒç´ ç±»å‹
        first_subtitle = entry['subtitles'][0]
        if isinstance(first_subtitle, str):
            # å¦‚æœsubtitlesä¸­æ˜¯å­—ç¬¦ä¸²ï¼Œè¯´æ˜è¿™æ˜¯äºŒçº§æ ‡é¢˜
            return (2, None)
        elif isinstance(first_subtitle, dict) and 'subtitles' in first_subtitle:
            # å¦‚æœsubtitlesä¸­çš„å…ƒç´ è¿˜æœ‰subtitlesï¼Œè¯´æ˜è¿™æ˜¯äºŒçº§æ ‡é¢˜
            return (2, None)
            
    # æ ¹æ®çˆ¶å±‚çº§åˆ¤æ–­
    if parent_level == 1:
        return (2, None)  # ä¸€çº§æ ‡é¢˜ä¸‹çš„æ ‡é¢˜ä¸ºäºŒçº§æ ‡é¢˜
    elif parent_level == 2:
        return (3, None)  # äºŒçº§æ ‡é¢˜ä¸‹çš„æ ‡é¢˜ä¸ºä¸‰çº§æ ‡é¢˜
    elif parent_level == 3:
        return (4, None)  # ä¸‰çº§æ ‡é¢˜ä¸‹çš„æ ‡é¢˜ä¸ºå››çº§æ ‡é¢˜
        
    return (4, None)  # é»˜è®¤æƒ…å†µä¸ºå››çº§æ ‡é¢˜

def is_title_match(md_title: str, json_title: str) -> Tuple[bool, float, bool]:
    """åˆ¤æ–­ä¸¤ä¸ªæ ‡é¢˜æ˜¯å¦åŒ¹é…ï¼Œè¿”å›(æ˜¯å¦åŒ¹é…, ç›¸ä¼¼åº¦, æ˜¯å¦å®Œå…¨åŒ¹é…)
    åŒ¹é…ä¼˜å…ˆçº§ï¼š
    1. å®Œå…¨åŒ¹é…ï¼ˆåŒ…æ‹¬ä¸­æ–‡éƒ¨åˆ†å®Œå…¨åŒ¹é…ï¼‰
    2. æ¨¡ç³ŠåŒ¹é…ï¼ˆä½¿ç”¨rapidfuzzï¼‰
    3. åŒ…å«å…³ç³»
    """
    # æå–ä¸­æ–‡éƒ¨åˆ†
    md_chinese = extract_chinese(md_title)
    json_chinese = extract_chinese(json_title)
    
    # 1. å®Œå…¨åŒ¹é…
    if md_title == json_title:
        return True, 1.0, True
    if md_chinese == json_chinese:
        return True, 1.0, True
        
    # 2. æ¨¡ç³ŠåŒ¹é…
    similarity = fuzz.ratio(md_chinese, json_chinese) / 100.0
    if similarity >= 0.8:
        return True, similarity, False
        
    # 3. åŒ…å«å…³ç³»
    if json_chinese in md_chinese:
        return True, 0.9, False
        
    return False, 0.0, False

def process_json_titles(titles_json: List) -> List[Tuple[str, int, int, str]]:
    """å¤„ç†JSONæ ‡é¢˜ï¼Œè¿”å›(æ ‡é¢˜, å±‚çº§, åŸå§‹ç´¢å¼•, çˆ¶æ ‡é¢˜)çš„åˆ—è¡¨"""
    result = []
    
    def process_entry(entry: dict, index: int, parent: str = None, parent_level: int = 0, is_top_level: bool = False, is_in_third_level: bool = False):
        if isinstance(entry, str):
            # æ ¹æ®çˆ¶å±‚çº§å’Œæ˜¯å¦åœ¨ç¬¬ä¸‰å±‚ç¡®å®šå­—ç¬¦ä¸²æ ‡é¢˜çš„å±‚çº§
            level, _ = get_title_level(entry, is_top_level, parent_level, is_in_third_level)
            result.append((entry, level, index, parent))
            return
            
        title = entry.get('title', '')
        if not title:
            return
            
        # è·å–å½“å‰æ ‡é¢˜çš„å±‚çº§
        level, _ = get_title_level(entry, is_top_level, parent_level, is_in_third_level)
        result.append((title, level, index, parent))
        
        # å¤„ç†å­æ ‡é¢˜
        if 'subtitles' in entry:
            # æ£€æŸ¥æ˜¯å¦åœ¨ç¬¬ä¸‰å±‚
            # å¦‚æœå½“å‰æ˜¯äºŒçº§æ ‡é¢˜ï¼Œé‚£ä¹ˆå®ƒçš„subtitlesä¸­çš„å­—ç¬¦ä¸²å°±æ˜¯ä¸‰çº§æ ‡é¢˜
            is_third_level = level == 2
            
            for sub in entry['subtitles']:
                if isinstance(sub, str):
                    # å­—ç¬¦ä¸²ç±»å‹çš„å­æ ‡é¢˜ï¼Œæ ¹æ®å½“å‰å±‚çº§å’Œæ˜¯å¦åœ¨ç¬¬ä¸‰å±‚ç¡®å®šå…¶å±‚çº§
                    sub_level, _ = get_title_level(sub, False, level, is_third_level)
                    result.append((sub, sub_level, index, title))
                else:
                    # é€’å½’å¤„ç†å­æ ‡é¢˜ï¼Œéé¡¶çº§
                    process_entry(sub, index, title, level, False, is_third_level)
    
    # å¤„ç†æ‰€æœ‰æ ‡é¢˜
    for i, entry in enumerate(titles_json):
        # å¤„ç†é¡¶çº§æ ‡é¢˜
        process_entry(entry, i, None, 0, True, False)
        # æ‰“å°æ¯ä¸ªæ ‡é¢˜çš„å±‚çº§ä¿¡æ¯ï¼Œç”¨äºè°ƒè¯•
        level, _ = get_title_level(entry, True)
        print(f"JSONæ ‡é¢˜: '{entry.get('title', '')}' -> å±‚çº§: {level} (é¡¶çº§æ ‡é¢˜)")
    
    return result

def find_best_match_in_range(md_titles: List[Tuple[str, int, int]], start_title: str, end_title: str, target_title: str, level: int, api_key: str) -> Tuple[int, float, int]:
    """åœ¨æŒ‡å®šèŒƒå›´å†…æŸ¥æ‰¾æœ€ä½³åŒ¹é…
    Args:
        md_titles: Markdownæ ‡é¢˜åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸º(æ ‡é¢˜æ–‡æœ¬, è¡Œå·, å±‚çº§)
        start_title: å¼€å§‹æ ‡é¢˜ï¼ˆç›®æ ‡æ ‡é¢˜åœ¨JSONä¸­çš„å‰ä¸€ä¸ªæ ‡é¢˜ï¼‰
        end_title: ç»“æŸæ ‡é¢˜ï¼ˆç›®æ ‡æ ‡é¢˜åœ¨JSONä¸­çš„åä¸€ä¸ªæ ‡é¢˜ï¼‰
        target_title: ç›®æ ‡æ ‡é¢˜
        level: ç›®æ ‡æ ‡é¢˜çš„å±‚çº§
        api_key: DeepSeek APIå¯†é’¥
    Returns:
        Tuple[int, float, int]: (æœ€ä½³åŒ¹é…è¡Œå·, ç›¸ä¼¼åº¦, åŒ¹é…çš„å±‚çº§)
    """
    # ç¡®ä¿è¾“å…¥æœ‰æ•ˆ
    if not md_titles:
        print("è­¦å‘Šï¼šmd_titlesåˆ—è¡¨ä¸ºç©º")
        return -1, 0.0, -1
    
    # æ‰¾åˆ°å¼€å§‹å’Œç»“æŸçš„è¡Œå·
    start_line = 0
    end_line = len(md_titles) - 1  # ä½¿ç”¨åˆ—è¡¨é•¿åº¦ä½œä¸ºé»˜è®¤ç»“æŸä½ç½®
    
    print(f"\nå¼€å§‹åŒ¹é…æ ‡é¢˜: '{target_title}' (ç›®æ ‡å±‚çº§: {level})")
    print(f"æœç´¢èŒƒå›´ï¼šä»æ ‡é¢˜ '{start_title}' åˆ° '{end_title}'")
    
    # æ‰¾åˆ°å¼€å§‹æ ‡é¢˜çš„è¡Œå·ï¼ˆç›®æ ‡æ ‡é¢˜åœ¨JSONä¸­çš„å‰ä¸€ä¸ªæ ‡é¢˜ï¼‰
    if start_title:
        for md_title, line_num, _ in md_titles:
            if is_title_match(md_title, start_title)[0]:
                start_line = line_num  # ä»å½“å‰è¡Œå¼€å§‹æœç´¢
                print(f"æ‰¾åˆ°èµ·å§‹æ ‡é¢˜ '{start_title}' åœ¨è¡Œå·: {line_num}")
                break
    
    # æ‰¾åˆ°ç»“æŸæ ‡é¢˜çš„è¡Œå·ï¼ˆç›®æ ‡æ ‡é¢˜åœ¨JSONä¸­çš„åä¸€ä¸ªæ ‡é¢˜ï¼‰
    if end_title:
        for md_title, line_num, _ in md_titles:
            if is_title_match(md_title, end_title)[0]:
                end_line = line_num - 1  # åˆ°å‰ä¸€è¡Œç»“æŸæœç´¢
                print(f"æ‰¾åˆ°ç»“æŸæ ‡é¢˜ '{end_title}' åœ¨è¡Œå·: {line_num}")
                break
    
    print(f"å®é™…æœç´¢èŒƒå›´ï¼šè¡Œå· {start_line} åˆ° {end_line}")
    
    # ç›´æ¥ä½¿ç”¨å®Œæ•´çš„ç›®æ ‡æ ‡é¢˜
    print(f"ç›®æ ‡æ ‡é¢˜: '{target_title}'")
    
    # æ ¹æ®ç›®æ ‡æ ‡é¢˜çº§åˆ«æ‰§è¡Œä¸åŒçš„æœç´¢ç­–ç•¥
    if level == 1:  # ä¸€çº§æ ‡é¢˜
        print("\nç›®æ ‡æ˜¯ä¸€çº§æ ‡é¢˜ï¼ŒæŒ‰é¡ºåºæœç´¢ï¼š")
        print("1. å…ˆæœç´¢äºŒçº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(2, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n2. æœªæ‰¾åˆ°åŒ¹é…çš„äºŒçº§æ ‡é¢˜ï¼Œæœç´¢ä¸‰çº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(3, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n3. æœªæ‰¾åˆ°åŒ¹é…çš„ä¸‰çº§æ ‡é¢˜ï¼Œæœç´¢å››çº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(4, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n4. æ‰€æœ‰çº§åˆ«çš„æ ‡é¢˜éƒ½æœªæ‰¾åˆ°åŒ¹é…ï¼Œå°è¯•åœ¨å†…å®¹ä¸­æŸ¥æ‰¾æ’å…¥ä½ç½®")
        with open("aligned_output.md", 'r', encoding='utf-8') as f:
            content = f.readlines()
        # ç›´æ¥è¿”å›-1ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨åœ¨process_unmatched_titlesä¸­å¤„ç†æ‰€æœ‰æœªåŒ¹é…çš„æ ‡é¢˜
        return -1, 0.0, -1
            
    elif level == 2:  # äºŒçº§æ ‡é¢˜
        print("\nç›®æ ‡æ˜¯äºŒçº§æ ‡é¢˜ï¼ŒæŒ‰é¡ºåºæœç´¢ï¼š")
        print("1. å…ˆæœç´¢ä¸‰çº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(3, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n2. æœªæ‰¾åˆ°åŒ¹é…çš„ä¸‰çº§æ ‡é¢˜ï¼Œæœç´¢å››çº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(4, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n3. æ‰€æœ‰çº§åˆ«çš„æ ‡é¢˜éƒ½æœªæ‰¾åˆ°åŒ¹é…ï¼Œå°è¯•åœ¨å†…å®¹ä¸­æŸ¥æ‰¾æ’å…¥ä½ç½®")
        with open("aligned_output.md", 'r', encoding='utf-8') as f:
            content = f.readlines()
        # ç›´æ¥è¿”å›-1ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨åœ¨process_unmatched_titlesä¸­å¤„ç†æ‰€æœ‰æœªåŒ¹é…çš„æ ‡é¢˜
        return -1, 0.0, -1
            
    elif level == 3:  # ä¸‰çº§æ ‡é¢˜
        print("\nç›®æ ‡æ˜¯ä¸‰çº§æ ‡é¢˜ï¼ŒæŒ‰é¡ºåºæœç´¢ï¼š")
        print("1. æœç´¢å››çº§æ ‡é¢˜")
        best_line, best_similarity, best_level = search_level_titles(4, target_title, md_titles, start_line, end_line, start_title, end_title, api_key)
        if best_line != -1:
            return best_line, best_similarity, best_level
            
        print("\n2. æœªæ‰¾åˆ°åŒ¹é…çš„å››çº§æ ‡é¢˜ï¼Œå°è¯•åœ¨å†…å®¹ä¸­æŸ¥æ‰¾æ’å…¥ä½ç½®")
        with open("aligned_output.md", 'r', encoding='utf-8') as f:
            content = f.readlines()
        # ç›´æ¥è¿”å›-1ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨åœ¨process_unmatched_titlesä¸­å¤„ç†æ‰€æœ‰æœªåŒ¹é…çš„æ ‡é¢˜
        return -1, 0.0, -1
    
    return -1, 0.0, -1

def align_titles(content: str, titles_json_path: str, output_md_path: str) -> Tuple[bool, List[Tuple[str, int, int, str, str, str]]]:
    """å¯¹é½æ ‡é¢˜å¹¶è¿”å›æœªåŒ¹é…çš„æ ‡é¢˜åˆ—è¡¨ï¼ˆå«å‰åæ ‡é¢˜ä¿¡æ¯ï¼‰
    Returns:
        Tuple[bool, List[Tuple[str, int, int, str, str, str]]]: (æ˜¯å¦æˆåŠŸ, æœªåŒ¹é…çš„æ ‡é¢˜åˆ—è¡¨ï¼Œæ¯é¡¹ä¸º(æ ‡é¢˜, å±‚çº§, åŸå§‹ç´¢å¼•, çˆ¶æ ‡é¢˜, prev_title, next_title))
    """
    try:
        with open(titles_json_path, 'r', encoding='utf-8') as f:
            titles_json = json.load(f)
        print(f"æˆåŠŸè¯»å–JSONæ–‡ä»¶ï¼ŒåŒ…å« {len(titles_json)} ä¸ªæ ‡é¢˜")
        json_titles = process_json_titles(titles_json)
        print(f"å¤„ç†åçš„JSONæ ‡é¢˜æ•°é‡: {len(json_titles)}")
        lines = content.splitlines(True)
        heading_re = re.compile(r'^(#+)\s*(.+?)\s*$')
        processed_lines = list(lines)
        md_titles = []  # (æ ‡é¢˜æ–‡æœ¬, è¡Œå·, åŸå§‹å±‚çº§)
        for i, line in enumerate(lines):
            m = heading_re.match(line)
            if m:
                level = len(m.group(1))
                title = m.group(2).strip()
                md_titles.append((title, i, level))
        print(f"åœ¨MDæ–‡ä»¶ä¸­æ‰¾åˆ° {len(md_titles)} ä¸ªæ ‡é¢˜")
        matched_md_idx = set()  # å·²è¢«åŒ¹é…çš„mdæ ‡é¢˜è¡Œå·
        matched_json_idx = set()  # å·²è¢«åŒ¹é…çš„jsonæ ‡é¢˜ç´¢å¼•
        json2md = {}  # jsonç´¢å¼•->mdç´¢å¼•
        md2json = {}  # mdè¡Œå·->jsonç´¢å¼•
        unmatched_titles = []  # (json_title, json_level, json_index, parent, prev_title, next_title)
        md_ptr = 0  # mdæ ‡é¢˜æŒ‡é’ˆ
        for j, (json_title, json_level, json_index, parent) in enumerate(json_titles):
            # 1. ç²¾ç¡®åŒ¹é…
            found = False
            for m in range(md_ptr, len(md_titles)):
                md_title, md_line, md_level = md_titles[m]
                if md_line in matched_md_idx:
                    continue
                # å®Œå…¨ä¸€è‡´/ä¸­æ–‡ä¸€è‡´
                if md_title == json_title or extract_chinese(md_title) == extract_chinese(json_title):
                    processed_lines[md_line] = f"{'#'*json_level} {md_title}\n"
                    matched_md_idx.add(md_line)
                    matched_json_idx.add(j)
                    json2md[j] = md_line
                    md2json[md_line] = j
                    md_ptr = m + 1
                    print(f"ç²¾ç¡®åŒ¹é…: MDæ ‡é¢˜ '{md_title}' -> JSONæ ‡é¢˜ '{json_title}' (å±‚çº§: {json_level})")
                    found = True
                    break
            if found:
                continue
            # 2. æ¨¡ç³ŠåŒ¹é…
            best_m = -1
            best_sim = 0
            for m in range(md_ptr, len(md_titles)):
                md_title, md_line, md_level = md_titles[m]
                if md_line in matched_md_idx:
                    continue
                is_match, similarity, is_exact = is_title_match(md_title, json_title)
                if is_match and similarity > best_sim:
                    best_sim = similarity
                    best_m = m
            if best_m != -1:
                md_title, md_line, md_level = md_titles[best_m]
                processed_lines[md_line] = f"{'#'*json_level} {md_title}\n"
                matched_md_idx.add(md_line)
                matched_json_idx.add(j)
                json2md[j] = md_line
                md2json[md_line] = j
                md_ptr = best_m + 1
                print(f"æ¨¡ç³ŠåŒ¹é…: MDæ ‡é¢˜ '{md_title}' -> JSONæ ‡é¢˜ '{json_title}' (å±‚çº§: {json_level}, ç›¸ä¼¼åº¦: {best_sim:.2f})")
                continue
            # 3. æœªåŒ¹é…ï¼Œè®°å½•å‰åjsonæ ‡é¢˜
            prev_title = json_titles[j-1][0] if j > 0 else None
            next_title = json_titles[j+1][0] if j < len(json_titles)-1 else None
            unmatched_titles.append((json_title, json_level, json_index, parent, prev_title, next_title))
            print(f"æœªåŒ¹é…: JSONæ ‡é¢˜ '{json_title}' (å±‚çº§: {json_level})")
        # æœªåŒ¹é…çš„mdæ ‡é¢˜å…¨éƒ¨é™çº§ä¸º####
        for m, (md_title, md_line, md_level) in enumerate(md_titles):
            if md_line not in matched_md_idx:
                processed_lines[md_line] = f"#### {md_title}\n"
        # å†™å…¥è¾“å‡ºæ–‡ä»¶
        output_dir = os.path.dirname(output_md_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir)
        print(f"å‡†å¤‡å†™å…¥è¾“å‡ºæ–‡ä»¶: {output_md_path}")
        with open(output_md_path, 'w', encoding='utf-8') as f:
            f.writelines(processed_lines)
        print(f"æˆåŠŸå†™å…¥è¾“å‡ºæ–‡ä»¶ï¼Œå…± {len(processed_lines)} è¡Œ")
        return True, unmatched_titles
    except Exception as e:
        print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        import traceback
        print(f"é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False, []

def insert_title_at_line(lines: List[str], title: str, level: int, line_num: int):
    """åœ¨æŒ‡å®šè¡Œå·æ’å…¥æ–°æ ‡é¢˜"""
    new_title_line = f"{'#' * level} {title}\n"
    if 0 <= line_num <= len(lines):
        lines.insert(line_num, new_title_line)
        print(f"å·²å°†æ ‡é¢˜ '{title}' (å±‚çº§ {level}) æ’å…¥åˆ°è¡Œå· {line_num + 1}")
    else:
        print(f"è­¦å‘Šï¼šæ— æ•ˆçš„æ’å…¥è¡Œå· {line_num + 1}ï¼Œæ ‡é¢˜ '{title}' æœªæ’å…¥")

def find_adjacent_titles(titles_json: List, target_title: str) -> Tuple[str, str]:
    """æŸ¥æ‰¾ç›®æ ‡æ ‡é¢˜çš„å‰åæ ‡é¢˜
    Args:
        titles_json: JSONæ ‡é¢˜åˆ—è¡¨
        target_title: ç›®æ ‡æ ‡é¢˜
    Returns:
        Tuple[str, str]: (å‰ä¸€ä¸ªæ ‡é¢˜, åä¸€ä¸ªæ ‡é¢˜)
    """
    def flatten_titles(json_data: List) -> List[str]:
        """å°†JSONç»“æ„æ‰å¹³åŒ–ä¸ºæ ‡é¢˜åˆ—è¡¨"""
        titles = []
        for item in json_data:
            if isinstance(item, dict):
                if 'title' in item:
                    titles.append(item['title'])
                if 'subtitles' in item:
                    titles.extend(flatten_titles(item['subtitles']))
        return titles

    # å°†æ‰€æœ‰æ ‡é¢˜æ‰å¹³åŒ–ä¸ºåˆ—è¡¨
    all_titles = flatten_titles(titles_json)
    
    # æ‰¾åˆ°ç›®æ ‡æ ‡é¢˜çš„ç´¢å¼•
    try:
        target_index = all_titles.index(target_title)
    except ValueError:
        return None, None
    
    # è·å–å‰ä¸€ä¸ªæ ‡é¢˜
    prev_title = all_titles[target_index - 1] if target_index > 0 else None
    
    # è·å–åä¸€ä¸ªæ ‡é¢˜
    next_title = all_titles[target_index + 1] if target_index < len(all_titles) - 1 else None
    
    return prev_title, next_title

def find_next_title(titles_json: List, current_title: str, depth: int = 0) -> str:
    """é€’å½’æŸ¥æ‰¾å½“å‰æ ‡é¢˜åçš„ä¸‹ä¸€ä¸ªæ ‡é¢˜
    Args:
        titles_json: JSONæ ‡é¢˜åˆ—è¡¨
        current_title: å½“å‰æ ‡é¢˜
        depth: é€’å½’æ·±åº¦ï¼Œç”¨äºæ§åˆ¶æŸ¥æ‰¾èŒƒå›´
    Returns:
        str: æ‰¾åˆ°çš„ä¸‹ä¸€ä¸ªæ ‡é¢˜ï¼Œå¦‚æœæ²¡æ‰¾åˆ°åˆ™è¿”å›None
    """
    def flatten_titles(json_data: List) -> List[str]:
        """å°†JSONç»“æ„æ‰å¹³åŒ–ä¸ºæ ‡é¢˜åˆ—è¡¨"""
        titles = []
        for item in json_data:
            if isinstance(item, dict):
                if 'title' in item:
                    titles.append(item['title'])
                if 'subtitles' in item:
                    titles.extend(flatten_titles(item['subtitles']))
        return titles

    # å°†æ‰€æœ‰æ ‡é¢˜æ‰å¹³åŒ–ä¸ºåˆ—è¡¨
    all_titles = flatten_titles(titles_json)
    
    try:
        current_index = all_titles.index(current_title)
        # å¦‚æœå½“å‰æ ‡é¢˜ä¸æ˜¯æœ€åä¸€ä¸ªï¼Œè¿”å›ä¸‹ä¸€ä¸ªæ ‡é¢˜
        if current_index + 1 < len(all_titles):
            return all_titles[current_index + 1]
        return None
    except ValueError:
        return None

def parse_page_blocks(md_path: str) -> List[Tuple[str, List[str]]]:
    print(f"[parse_page_blocks] è§£æMDæ–‡ä»¶: {md_path}")
    page_blocks = []
    with open(md_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    i = 0
    while i < len(lines):
        line = lines[i].strip()
        if line.startswith('<page_idx:'):
            m = re.match(r'<page_idx:(\d+)>', line)
            if m:
                page_idx = m.group(1)
                i += 1
                while i < len(lines) and lines[i].strip() != '[':
                    i += 1
                i += 1
                content = []
                while i < len(lines) and lines[i].strip() != ']':
                    content.append(lines[i].rstrip('\n'))
                    i += 1
                page_blocks.append((page_idx, content))
        i += 1
    print(f"[parse_page_blocks] è§£æå®Œæˆï¼Œå…± {len(page_blocks)} ä¸ªé¡µå—")
    return page_blocks

def filter_page_blocks_by_lines(all_blocks, start_line, end_line, strict_only=False):
    """
    æ ¹æ®å…¨å±€è¡Œå·èŒƒå›´ï¼Œç­›é€‰å‡ºæ‰€æœ‰åœ¨ start_line ~ end_line èŒƒå›´å†…æœ‰äº¤é›†çš„é¡µå—ã€‚
    å¦‚æœæ²¡æœ‰äº¤é›†ï¼Œåˆ™è‡ªåŠ¨æ‰©å±•åç»­æœ€å¤š5ä¸ªé¡µå—ï¼ˆä»…åœ¨ strict_only=False æ—¶ï¼‰ã€‚
    strict_only: True æ—¶åªè¿”å›ä¸¥æ ¼äº¤é›†é¡µå—ï¼Œä¸åšæ‰©å±•ã€‚
    è¿”å›: [{"page_idx": é¡µå·, "content": [è¯¥é¡µå…¨éƒ¨æ®µè½è¡Œ]} ...]
    """
    result = []
    current_line = 0
    for page_idx, paras in all_blocks:
        page_start = current_line
        page_end = current_line + len(paras) - 1
        if page_end >= start_line and page_start <= end_line:
            result.append({"page_idx": page_idx, "content": paras})
        current_line += len(paras)
    if strict_only:
        return result
    # å¦‚æœæ²¡æœ‰ä»»ä½•é¡µå—è¢«é€‰ä¸­ï¼Œåˆ™æ‰©å±•åç»­æœ€å¤š5ä¸ªé¡µå—
    if not result:
        current_line = 0
        for page_idx, paras in all_blocks:
            page_start = current_line
            if page_start > start_line:
                result.append({"page_idx": page_idx, "content": paras})
                if len(result) >= 5:
                    break
            current_line += len(paras)
    return result

def process_unmatched_titles(aligned_md_path: str, unmatched_titles: List[Tuple[str, int, int, str, str, str]], titles_json: List, api_key: str) -> bool:
    print("[process_unmatched_titles] å¼€å§‹å¤„ç†æœªåŒ¹é…æ ‡é¢˜...")
    try:
        print(f"[process_unmatched_titles] æœªåŒ¹é…æ ‡é¢˜æ€»æ•°: {len(unmatched_titles)}")
        title_idx = 0
        while title_idx < len(unmatched_titles):
            with open(aligned_md_path, 'r', encoding='utf-8') as f:
                content = f.read()
            lines = content.splitlines(True)
            heading_re = re.compile(r'^(#+)\s*(.+?)\s*$')
            md_titles = []
            for line_idx, line in enumerate(lines):
                m = heading_re.match(line)
                if m:
                    level = len(m.group(1))
                    title = m.group(2).strip()
                    md_titles.append((title, line_idx, level))
            current_title_info = unmatched_titles[title_idx]
            json_title, json_level, json_index, parent, prev_title, next_title = current_title_info
            print(f"[process_unmatched_titles] å¤„ç†æœªåŒ¹é…æ ‡é¢˜: '{json_title}' (å±‚çº§: {json_level})")
            # æŸ¥æ‰¾ç‰©ç†ä½ç½®ä¸Šä¸‹æ–‡
            prev_line = 0
            next_line = len(lines) - 1
            # æ‰¾åˆ°å‰ä¸€ä¸ªæ ‡é¢˜çš„è¡Œå·
            if prev_title:
                for md_title, line_num, _ in md_titles:
                    if extract_chinese(md_title) == extract_chinese(prev_title):
                        prev_line = line_num
                        break
            # æ‰¾åˆ°åä¸€ä¸ªæ ‡é¢˜çš„è¡Œå·
            if next_title:
                for md_title, line_num, _ in md_titles:
                    if extract_chinese(md_title) == extract_chinese(next_title):
                        next_line = line_num
                        break
            # è‡ªåŠ¨æ‰©å±•end_lineï¼Œä¿è¯LLMèƒ½çœ‹åˆ°æ­£æ–‡
            # å¦‚æœèŒƒå›´å¤ªå°ï¼ˆå¦‚åªè¦†ç›–1-2é¡µï¼‰ï¼Œåˆ™æ‰©å±•åˆ°æ–‡æ¡£ç»“å°¾æˆ–å¤šç»™å‡ é¡µ
            all_page_blocks = parse_page_blocks(aligned_md_path)
            print(f"[process_unmatched_titles] è§£æå‡º {len(all_page_blocks)} ä¸ªé¡µå—")
            # ç»Ÿè®¡èŒƒå›´å†…é¡µæ•°
            # æ–°å¢ï¼šä¸¥æ ¼èŒƒå›´é¡µå—
            strict_page_blocks = filter_page_blocks_by_lines(all_page_blocks, prev_line, next_line, strict_only=True)
            strict_page_range = [int(page['page_idx']) for page in strict_page_blocks]
            # å®½æ¾èŒƒå›´ç”¨äºå†…å®¹ç”Ÿæˆ
            page_blocks_in_range = filter_page_blocks_by_lines(all_page_blocks, prev_line, next_line)
            if len(page_blocks_in_range) <= 2:
                # æ‰©å±•åˆ°æ–‡æ¡£ç»“å°¾æˆ–å¤šç»™5é¡µ
                last_line = len(lines) - 1
                next_line = min(last_line, prev_line + 200)  # 200è¡Œæˆ–ç»“å°¾
                page_blocks_in_range = filter_page_blocks_by_lines(all_page_blocks, prev_line, next_line)
            # ç”Ÿæˆ page_blocks_strï¼Œä¿ç•™åŸå§‹ Markdown å±‚çº§å’Œå…¨å±€è¡Œå·ï¼Œå¹¶æ ‡è®°ç±»å‹
            # å…ˆæ„å»ºå…¨å±€è¡Œå·åˆ°å†…å®¹çš„æ˜ å°„
            line_to_type = {}
            for idx, line in enumerate(lines):
                m = heading_re.match(line)
                if m:
                    line_to_type[idx] = '[æ ‡é¢˜]'
                else:
                    line_to_type[idx] = '[æ­£æ–‡]'
            # ç”Ÿæˆ page_blocks_str
            if not page_blocks_in_range:
                print("[process_unmatched_titles] æ²¡æœ‰æ‰¾åˆ°ä»»ä½•åˆ†é¡µå†…å®¹å—ï¼Œå°†ç›´æ¥æˆªå–åŸå§‹è¡ŒèŒƒå›´")
                raw_lines = lines[prev_line:next_line+1]
                page_blocks_str = "\n".join([
                    f"{i+prev_line+1}. [RAW] {line.rstrip()}" for i, line in enumerate(raw_lines)
                ])
            else:
                # ä¿ç•™åŸæœ‰é€»è¾‘
                page_blocks_str = ""
                for page in page_blocks_in_range:
                    page_idx = page['page_idx']
                    content_lines = []
                    last_found = prev_line - 1
                    for i, line in enumerate(page['content']):
                        search_start = prev_line if i == 0 else last_found+1
                        found = False
                        for j in range(search_start, len(lines)):
                            if lines[j].strip('\n') == line.strip('\n'):
                                global_line_no = j
                                last_found = j
                                found = True
                                break
                        if not found:
                            global_line_no = prev_line + i
                        type_tag = line_to_type.get(global_line_no, '[æ­£æ–‡]')
                        content_lines.append(f"{global_line_no+1}. {type_tag} {lines[global_line_no].rstrip()}" if found else f"?. {type_tag} {line.rstrip()}")
                    page_blocks_str += f"ç¬¬{page_idx}é¡µ:\n" + "\n".join(content_lines) + "\n"

            # æ‰“å°æœ¬æ¬¡æœç´¢èŒƒå›´å’Œå‰åæ ‡é¢˜è¡Œå·
            print(f"[process_unmatched_titles] LLMæœç´¢èŒƒå›´ï¼šå…¨å±€è¡Œå· {prev_line} åˆ° {next_line}ï¼Œä¸¥æ ¼é¡µç èŒƒå›´ {strict_page_range} (prev_title='{prev_title}'@{prev_line}, next_title='{next_title}'@{next_line})")

            # æ–°promptï¼ˆè¦†ç›–å’Œæ›¿æ¢ï¼‰
            prompt = f'''
ä½ éœ€è¦å¸®åŠ©æˆ‘ä»¬åˆ¤æ–­ä¸€ä¸ªæ ‡é¢˜åº”è¯¥æ’å…¥åœ¨æ–‡æ¡£çš„å“ªä¸ªä½ç½®ã€‚

ç›®æ ‡æ ‡é¢˜æ˜¯ï¼š"{json_title}" (å±‚çº§: {json_level})

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
    â€¢ å¼€å§‹æ ‡é¢˜ï¼š"{prev_title}"
    â€¢ ç»“æŸæ ‡é¢˜ï¼š"{next_title}"

ä»¥ä¸‹æ˜¯è¯¥æ ‡é¢˜å¯æ’å…¥çš„æ–‡æ¡£èŒƒå›´å†…å®¹ï¼Œå·²æŒ‰é¡µåˆ†å—æ˜¾ç¤ºã€‚æ¯ä¸€é¡µé‡ŒåŒ…å«åŸå§‹çš„Markdownè¡Œï¼Œä¿ç•™äº†æ‰€æœ‰çš„#ã€##ã€###å±‚çº§æ ‡è®°ï¼Œä»¥åŠæ¯è¡Œçš„è¡Œå·ã€‚è¯·ä»”ç»†é˜…è¯»ï¼š

{page_blocks_str}

ã€åˆ†æä»»åŠ¡èƒŒæ™¯ã€‘
è¯¥æœªåŒ¹é…æ ‡é¢˜å‡ºç°åœ¨ç›®å½•ç»“æ„ä¸­â€œ{prev_title}â€å’Œâ€œ{next_title}â€ä¹‹é—´ã€‚è¿™ä¸ªæ ‡é¢˜å¯èƒ½æ˜¯ä¸ºäº†â€œæ€»æ½â€æˆ–â€œæ¦‚æ‹¬â€è¿™éƒ¨åˆ†å†…å®¹ï¼Œä¹Ÿå¯èƒ½æ˜¯ä¸ºäº†è¡¥å……å…·ä½“â€œå†…å®¹æ€§â€ç»†èŠ‚ã€‚

ã€åˆ†ææ­¥éª¤è¦æ±‚ã€‘
1ï¸âƒ£ å…ˆå¯¹æä¾›çš„èŒƒå›´å†…å®¹é€æ®µé€è¡Œè¿›è¡Œåˆ†ææ€»ç»“ï¼Œæ ‡æ³¨æ‰€æœ‰æ ‡é¢˜å’Œæ­£æ–‡çš„ä¸»é¢˜ç‚¹ã€‚
2ï¸âƒ£ è¯„ä¼°è¯¥èŒƒå›´å†…å®¹æ˜¯å¦å­˜åœ¨ç¼ºå¤±çš„æ€»æ½æ€§ä¸»é¢˜ï¼Œç›®æ ‡æ ‡é¢˜èƒ½å¦ä½œä¸ºæ­¤èŒƒå›´çš„æ€»æ½æˆ–æ¦‚æ‹¬æ ‡é¢˜ã€‚
3ï¸âƒ£ åŒæ—¶åˆ†ææ˜¯å¦æœ‰éœ€è¦åœ¨å†…å®¹æ€§ç»†èŠ‚é‡Œæ’å…¥è¯¥æ ‡é¢˜çš„ä½ç½®ï¼Œä½¿å…¶ä¸ä¸Šä¸‹æ–‡ç´§å¯†è¡”æ¥ã€‚
4ï¸âƒ£ åœ¨ä¸¤ç§è§’åº¦ï¼ˆæ€»æ½æ€§ä¸å†…å®¹æ€§ï¼‰éƒ½åˆ†æåï¼Œç»™å‡ºæœ€åˆç†çš„æ’å…¥ä½ç½®å»ºè®®ã€‚

ã€è¾“å‡ºæ ¼å¼è¦æ±‚ã€‘

âœ… ä½ åªèƒ½è¾“å‡ºå¦‚ä¸‹æ ¼å¼ï¼š
æ’å…¥å…¨å±€è¡Œå·ï¼š<è¡Œå·>
æ’å…¥é¡µç ï¼š<é¡µç >
åŸå› ï¼š<è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬å¯¹èŒƒå›´å†…å®¹çš„æ€»ç»“ã€æ€»æ½æ€§åˆ†æã€å†…å®¹æ€§åˆ†æã€æœ€ç»ˆå†³ç­–ç†ç”±>

ğŸš« å¦‚æœåœ¨æ‰€æœ‰è¡Œéƒ½æ²¡æœ‰åˆé€‚ä½ç½®ï¼Œè¯·ä¸¥æ ¼è¾“å‡ºï¼š
æ’å…¥ä½ç½®ï¼šæ— 
åŸå› ï¼š<è¯¦ç»†è¯´æ˜ä¸ºä»€ä¹ˆèŒƒå›´å†…æ²¡æœ‰ä»»ä½•ä½ç½®é€‚åˆä½œä¸ºæ’å…¥ç‚¹ï¼Œå¹¶æ€»ç»“å†…å®¹åˆ†æ>

âš ï¸ ä¸¥ç¦è¾“å‡ºé¡µç +è¡Œå·æ ¼å¼ï¼Œåªèƒ½è¾“å‡º"æ’å…¥å…¨å±€è¡Œå·ï¼š<è¡Œå·>"ï¼å¦åˆ™ä¼šè¢«åˆ¤ä¸ºæ— æ•ˆç­”æ¡ˆã€‚
'''
            print(f"[process_unmatched_titles] è°ƒç”¨DeepSeek R1åˆ¤æ–­æ’å…¥ä½ç½®...\nPromptå†…å®¹å¦‚ä¸‹:\n{prompt}")
            response = deepseek_api(prompt, api_key, system_prompt=SYSTEM_PROMPT_INSERT_POSITION, use_r1=True)
            print(f"[process_unmatched_titles] DeepSeek R1è¿”å›: {response}")
            if not response:
                print("[process_unmatched_titles] APIè°ƒç”¨å¤±è´¥")
                title_idx += 1
                continue
            if "æ’å…¥ä½ç½®ï¼šæ— " in response:
                print(f"[process_unmatched_titles] æ ‡é¢˜ '{json_title}' æœªæ‰¾åˆ°åˆé€‚çš„æ’å…¥ä½ç½®")
                title_idx += 1
                continue
            # åªå…è®¸è§£æã€Œæ’å…¥å…¨å±€è¡Œå·ï¼š<è¡Œå·>ã€
            global_line_match = re.search(r'æ’å…¥å…¨å±€è¡Œå·[:ï¼š]\s*(\d+)', response)
            if global_line_match:
                global_line = int(global_line_match.group(1))
                if not (prev_line <= global_line <= next_line):
                    print(f"[process_unmatched_titles] DeepSeek R1è¿”å›çš„å…¨å±€è¡Œå· {global_line} ä¸åœ¨å…è®¸èŒƒå›´ {prev_line}~{next_line}ï¼Œå°†ä½¿ç”¨èŒƒå›´èµ·ç‚¹ä½œä¸ºå…œåº•æ’å…¥ä½ç½®ã€‚")
                    global_line = prev_line
                insert_title_at_line(lines, json_title, json_level, global_line)
                with open(aligned_md_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                print(f"å·²å°†æ ‡é¢˜ '{json_title}' (å±‚çº§ {json_level}) æ’å…¥åˆ°è¡Œå· {global_line}")
            else:
                print(f"[process_unmatched_titles] DeepSeek R1è¾“å‡ºæ ¼å¼ä¸è§„èŒƒï¼Œæœªæ‰¾åˆ°å¯ç”¨è¡Œå·ï¼Œå°†å°è¯•åœ¨èŒƒå›´èµ·ç‚¹æ’å…¥ã€‚")
                insert_title_at_line(lines, json_title, json_level, prev_line)
                with open(aligned_md_path, 'w', encoding='utf-8') as f:
                    f.writelines(lines)
                print(f"å·²å°†æ ‡é¢˜ '{json_title}' (å±‚çº§ {json_level}) ä½œä¸ºæ€»æ½æ€§æ ‡é¢˜æ’å…¥åˆ°èŒƒå›´èµ·ç‚¹è¡Œå· {prev_line}")
            title_idx += 1
        print("[process_unmatched_titles] æ‰€æœ‰æœªåŒ¹é…æ ‡é¢˜å¤„ç†å®Œæˆã€‚\n")
        return True
    except Exception as e:
        print(f"[process_unmatched_titles] å¤„ç†æœªåŒ¹é…æ ‡é¢˜æ—¶å‡ºé”™: {str(e)}")
        import traceback
        print(f"[process_unmatched_titles] é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
        return False

def search_level_titles(target_level: int, target_title: str, md_titles: List[Tuple[str, int, int]], start_line: int, end_line: int, prev_title: str, next_title: str, api_key: str) -> Tuple[int, float, int]:
    """åœ¨æŒ‡å®šèŒƒå›´å†…æœç´¢ç‰¹å®šçº§åˆ«çš„æ ‡é¢˜"""
    level_titles = []
    for md_title, line_num, md_level in md_titles:
        if line_num < start_line or line_num > end_line:
            continue
        if md_level == target_level:
            level_titles.append((md_title, line_num, md_level))
            print(f"æ‰¾åˆ°å€™é€‰æ ‡é¢˜: '{md_title}' (è¡Œå·: {line_num}, çº§åˆ«: {md_level})")
    
    if level_titles:
        print(f"\nåœ¨èŒƒå›´å†…æ‰¾åˆ° {len(level_titles)} ä¸ª {target_level} çº§æ ‡é¢˜")
        # ç›´æ¥è¿”å›-1ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨åœ¨process_unmatched_titlesä¸­å¤„ç†æ‰€æœ‰æœªåŒ¹é…çš„æ ‡é¢˜
        return -1, 0.0, -1
    else:
        print(f"\nåœ¨èŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½• {target_level} çº§æ ‡é¢˜")
        # ç›´æ¥è¿”å›-1ï¼Œå› ä¸ºæˆ‘ä»¬ç°åœ¨åœ¨process_unmatched_titlesä¸­å¤„ç†æ‰€æœ‰æœªåŒ¹é…çš„æ ‡é¢˜
        return -1, 0.0, -1

def process_directory(base_path: str, api_key: str):
    """
    å¤„ç†ç›®å½•ä¸‹çš„æ‰€æœ‰markdownæ–‡ä»¶
    :param base_path: åŸºç¡€è·¯å¾„
    :param api_key: DeepSeek APIå¯†é’¥
    """
    base_path = Path(base_path)
    
    # è·å–md_filesç›®å½•
    md_files_dir = base_path / "md_files"
    if not md_files_dir.exists():
        print(f"é”™è¯¯ï¼šæœªæ‰¾åˆ°md_filesç›®å½•: {md_files_dir}")
        return
    
    print(f"\nå¼€å§‹å¤„ç†ç›®å½•: {md_files_dir}")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_files = 0
    processed_files = 0
    failed_files = 0
    
    # éå†æ‰€æœ‰å­ç›®å½•
    for report_dir in md_files_dir.iterdir():
        if report_dir.is_dir():
            # æ£€æŸ¥ç›®å½•åç§°æ ¼å¼
            parts = report_dir.name.split('_')
            if len(parts) < 3:  # è‡³å°‘éœ€è¦è‚¡ç¥¨ä»£ç ã€å…¬å¸åå’ŒæŠ¥å‘Šå
                print(f"è­¦å‘Šï¼šç›®å½•åç§°æ ¼å¼ä¸æ­£ç¡®: {report_dir.name}")
                continue
                
            # æ£€æŸ¥ç¬¬ä¸€éƒ¨åˆ†æ˜¯å¦ä¸ºæ—¥æœŸï¼ˆ8ä½æ•°å­—ï¼‰
            is_date_format = len(parts[0]) == 8 and parts[0].isdigit()
            
            # æŸ¥æ‰¾å¤„ç†åçš„markdownæ–‡ä»¶å’Œtitles.jsonæ–‡ä»¶
            processed_md = next(report_dir.glob("*_without_toc_processed.md"), None)
            titles_json = next(report_dir.glob("titles.json"), None)
            
            if not processed_md or not titles_json:
                print(f"è­¦å‘Šï¼šåœ¨ {report_dir} ä¸­æœªæ‰¾åˆ°å¿…è¦çš„æ–‡ä»¶")
                continue
            
            total_files += 1
            print(f"\nå¤„ç†æ–‡ä»¶: {processed_md}")
            
            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(processed_md, 'r', encoding='utf-8') as f:
                    content = f.read()
                with open(titles_json, 'r', encoding='utf-8') as f:
                    titles = json.load(f)
                
                # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
                output_md = report_dir / f"{report_dir.name}_align.md"
                
                # å¯¹é½æ ‡é¢˜
                success, unmatched_titles = align_titles(content, str(titles_json), str(output_md))
                
                if success:
                    # å¤„ç†æœªåŒ¹é…çš„æ ‡é¢˜
                    if unmatched_titles:
                        process_unmatched_titles(str(output_md), unmatched_titles, titles, api_key)
                    processed_files += 1
                else:
                    failed_files += 1
                    
            except Exception as e:
                print(f"å¤„ç†æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
                failed_files += 1
                continue
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print(f"\nå¤„ç†å®Œæˆï¼ç»Ÿè®¡ä¿¡æ¯:")
    print(f"- æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"- æˆåŠŸå¤„ç†: {processed_files}")
    print(f"- å¤„ç†å¤±è´¥: {failed_files}")

def write_page_blocks(page_blocks: List[Tuple[str, List[str]]], out_path: str):
    print(f"[write_page_blocks] å†™å…¥MDæ–‡ä»¶: {out_path}ï¼Œå…± {len(page_blocks)} ä¸ªé¡µå—")
    with open(out_path, 'w', encoding='utf-8') as f:
        for page_idx, paragraphs in page_blocks:
            f.write(f'<page_idx:{page_idx}>\n[\n')
            for para in paragraphs:
                f.write(para + '\n')
            f.write(']\n\n')
    print(f"[write_page_blocks] å†™å…¥å®Œæˆã€‚\n")

def align_titles_in_lines(paragraphs, titles_json, api_key=None):
    print("[align_titles_in_lines] å¼€å§‹å¯¹é½æ®µè½æ ‡é¢˜...")
    heading_re = re.compile(r'^(#+)\s*(.+?)\s*$')
    md_titles = []
    for idx, para in enumerate(paragraphs):
        m = heading_re.match(para)
        if m:
            level = len(m.group(1))
            title = m.group(2).strip()
            md_titles.append((title, idx, level))
    print(f"[align_titles_in_lines] æ£€æµ‹åˆ° {len(md_titles)} ä¸ªMDæ ‡é¢˜")

    def flatten_titles(json_data, level=1):
        result = []
        for item in json_data:
            if isinstance(item, dict):
                title = item.get('title', '')
                if title:
                    result.append((title, level))
                if 'subtitles' in item:
                    result.extend(flatten_titles(item['subtitles'], level+1))
            elif isinstance(item, str):
                result.append((item, level))
        return result

    json_titles = flatten_titles(titles_json)
    json_title_texts = [t for t, _ in json_titles]
    json_title_levels = {t: l for t, l in json_titles}
    print(f"[align_titles_in_lines] JSONç›®å½•å…± {len(json_title_texts)} ä¸ªæ ‡é¢˜")

    aligned = list(paragraphs)
    used_json_titles = set()

    for idx, (md_title, para_idx, md_level) in enumerate(md_titles):
        print(f"[align_titles_in_lines] å¤„ç†MDæ ‡é¢˜: '{md_title}' (åŸå±‚çº§: {md_level})")
        if md_title in json_title_texts:
            json_level = json_title_levels[md_title]
            aligned[para_idx] = f"{'#'*json_level} {md_title}"
            used_json_titles.add(md_title)
            print(f"[align_titles_in_lines] å®Œå…¨åŒ¹é…: '{md_title}' -> å±‚çº§ {json_level}")
        else:
            candidates = rapidfuzz_process.extract(md_title, json_title_texts, scorer=fuzz.ratio, limit=3)
            print(f"[align_titles_in_lines] Top-3å€™é€‰: {candidates}")
            prompt = f"""ä½ æ˜¯ä¸€ä¸ªç»“æ„åŒ–æ–‡æ¡£æ ‡é¢˜å¯¹é½ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä»ç»™å®šçš„å€™é€‰æ ‡é¢˜åˆ—è¡¨ä¸­ï¼Œé€‰æ‹©æœ€ç¬¦åˆç›®æ ‡æ–‡æœ¬ä¸Šä¸‹æ–‡çš„æ ‡é¢˜ã€‚\nç›®æ ‡Markdownæ ‡é¢˜ï¼š{md_title}\n"""
            for i, (cand, score, _) in enumerate(candidates):
                prompt += f"å€™é€‰{i+1}: {cand} (ç›¸ä¼¼åº¦: {score})\n"
            prompt += "\nåªèƒ½ä»å€™é€‰ä¸­é€‰æ‹©ä¸€ä¸ªï¼Œä¸è¦ç”Ÿæˆæ–°æ ‡é¢˜ã€‚è¾“å‡ºæ ¼å¼ï¼šé€‰æ‹©ï¼š<ä½ é€‰çš„æ ‡é¢˜>"
            if api_key:
                print(f"[align_titles_in_lines] è°ƒç”¨DeepSeek R1è¿›è¡Œå€™é€‰é€‰æ‹©...")
                llm_result = deepseek_api(prompt, api_key, system_prompt=SYSTEM_PROMPT_SELECT_TITLE, use_r1=True)
                print(f"[align_titles_in_lines] DeepSeek R1è¿”å›: {llm_result}")
                match = re.search(r'é€‰æ‹©[:ï¼š]\s*(.+)', llm_result)
                if match:
                    llm_result = match.group(1).strip()
                else:
                    llm_result = llm_result.strip().split('\n')[0]
            else:
                llm_result = candidates[0][0]
            if llm_result in json_title_levels:
                json_level = json_title_levels[llm_result]
                aligned[para_idx] = f"{'#'*json_level} {llm_result}"
                used_json_titles.add(llm_result)
                print(f"[align_titles_in_lines] DeepSeek R1é€‰æ‹©: '{llm_result}' -> å±‚çº§ {json_level}")
            else:
                print(f"[align_titles_in_lines] DeepSeek R1æœªè¿”å›æœ‰æ•ˆæ ‡é¢˜ï¼Œä¿æŒåŸæ ·")
    print("[align_titles_in_lines] æ ‡é¢˜å¯¹é½å®Œæˆã€‚\n")
    return aligned

def align_titles_in_paragraphs(paragraphs, titles_json, api_key=None):
    return align_titles_in_lines(paragraphs, titles_json, api_key=api_key)

def main():
    print("[main] å¯åŠ¨ä¸»æµç¨‹...")
    input_md = '/Users/liucun/Desktop/yuancailiao/600801.SH-åæ–°æ°´æ³¥-2024å¹´åæ–°æ°´æ³¥ESGæŠ¥å‘Š/600801.SH-åæ–°æ°´æ³¥-2024å¹´åæ–°æ°´æ³¥ESGæŠ¥å‘Š_preprocessed.md'  # è¾“å…¥mdæ–‡ä»¶
    output_md = '/Users/liucun/Desktop/300573.SZ-å…´é½çœ¼è¯-2024å¹´åº¦ç¯å¢ƒ,ç¤¾ä¼šä¸æ²»ç†(ESG)æŠ¥å‘Š/markdown_aligned.md'   # è¾“å‡ºmdæ–‡ä»¶
    titles_json_path = '/Users/liucun/Desktop/300573.SZ-å…´é½çœ¼è¯-2024å¹´åº¦ç¯å¢ƒ,ç¤¾ä¼šä¸æ²»ç†(ESG)æŠ¥å‘Š/titles.json'  # ç›®å½•ç»“æ„json
    api_key = 'sk-igvmjaomyjwstzlsvtlktrpgsuqxdfqngaxizidcogdtgicu'

    print(f"[main] è¯»å–è¾“å…¥MD: {input_md}")
    with open(input_md, 'r', encoding='utf-8') as f:
        content = f.read()

    print(f"[main] è¯»å–ç›®å½•ç»“æ„: {titles_json_path}")
    with open(titles_json_path, 'r', encoding='utf-8') as f:
        titles_json = json.load(f)

    print("[main] å¯¹æ•´ä¸ªMDåšæ ‡é¢˜å¯¹é½ï¼ˆç²¾ç¡®+æ¨¡ç³Šï¼‰...")
    success, unmatched_titles = align_titles(content, titles_json_path, output_md)

    if success:
        print("[main] æ ‡é¢˜å¯¹é½å®Œæˆï¼Œå¤„ç†æœªåŒ¹é…æ ‡é¢˜ï¼ˆæ™ºèƒ½æ’å…¥ï¼‰...")
        if unmatched_titles:
            process_unmatched_titles(output_md, unmatched_titles, titles_json, api_key)
        print(f"[main] è¾“å‡ºå·²å†™å…¥: {output_md}")
    else:
        print("[main] æ ‡é¢˜å¯¹é½å¤±è´¥ï¼")
    print("[main] ä¸»æµç¨‹ç»“æŸã€‚\n")

if __name__ == '__main__':
    main()