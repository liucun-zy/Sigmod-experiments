import json
import os
import re
from collections import defaultdict
from urllib.parse import quote

def generate_cross_platform_paths(image_folder_path, image_filename, report_folder_path=None):
    """
    ç”Ÿæˆè·¨å¹³å°å…¼å®¹çš„å›¾ç‰‡è·¯å¾„
    
    Args:
        image_folder_path: å›¾ç‰‡æ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„
        image_filename: å›¾ç‰‡æ–‡ä»¶å
        report_folder_path: æŠ¥å‘Šæ–‡ä»¶å¤¹çš„å®Œæ•´è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºç”Ÿæˆç›¸å¯¹è·¯å¾„ï¼‰
    
    Returns:
        dict: åŒ…å«å„ç§æ ¼å¼è·¯å¾„çš„å­—å…¸
    """
    # æ„å»ºå®Œæ•´å›¾ç‰‡è·¯å¾„
    image_path = os.path.join(image_folder_path, image_filename)
    image_path = image_path.replace('\\', '/')
    
    # è·å–æ–‡ä»¶å¤¹åç§°
    image_folder_name = os.path.basename(image_folder_path)
    
    # ç”Ÿæˆå„ç§è·¯å¾„æ ¼å¼
    paths = {}
    
    try:
        # 1. Markdownæ ¼å¼ï¼ˆç›¸å¯¹è·¯å¾„ï¼‰
        paths['markdown'] = f"![]({image_folder_name}/{image_filename})"
        
        # 2. ç»å¯¹è·¯å¾„çš„file:// URL
        encoded_abs_path = quote(image_path, safe=':/')
        paths['file_url'] = f"file://{encoded_abs_path}"
        
        # 3. ç›¸å¯¹è·¯å¾„ï¼ˆä¼˜åŒ–é€»è¾‘ï¼‰
        if report_folder_path:
            # å¦‚æœæä¾›äº†æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä½¿ç”¨æŠ¥å‘Šæ–‡ä»¶å¤¹ä½œä¸ºåŸºå‡†
            try:
                relative_path = os.path.relpath(image_path, report_folder_path)
                paths['relative'] = relative_path.replace('\\', '/')
            except:
                # å¦‚æœç›¸å¯¹è·¯å¾„è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„ç›¸å¯¹è·¯å¾„
                paths['relative'] = f"{image_folder_name}/{image_filename}"
        else:
            # å¦‚æœæ²¡æœ‰æä¾›æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä½¿ç”¨ç®€å•çš„ç›¸å¯¹è·¯å¾„
            paths['relative'] = f"{image_folder_name}/{image_filename}"
        
        # 4. HTTPæœ¬åœ°æœåŠ¡å™¨é“¾æ¥
        # åªåŒ…å«å¿…è¦çš„è·¯å¾„éƒ¨åˆ†ï¼Œä¸åŒ…å«ä¸Šçº§ç›®å½•
        if report_folder_path:
            # æ£€æŸ¥å›¾ç‰‡æ–‡ä»¶å¤¹æ˜¯å¦åœ¨æŠ¥å‘Šæ–‡ä»¶å¤¹å†…éƒ¨
            # æ›´ç²¾ç¡®çš„æ£€æŸ¥ï¼šç¡®ä¿å›¾ç‰‡æ–‡ä»¶å¤¹æ˜¯æŠ¥å‘Šæ–‡ä»¶å¤¹çš„ç›´æ¥å­ç›®å½•
            report_folder_parent = os.path.dirname(image_folder_path)
            if report_folder_parent == report_folder_path:
                # å›¾ç‰‡æ–‡ä»¶å¤¹åœ¨æŠ¥å‘Šæ–‡ä»¶å¤¹å†…éƒ¨ï¼ˆå¦‚_pagesç›®å½•ï¼‰
                report_folder_name = os.path.basename(report_folder_path)
                http_path = quote(f"{report_folder_name}/{image_folder_name}/{image_filename}", safe='/')
            else:
                # å›¾ç‰‡æ–‡ä»¶å¤¹åœ¨æŠ¥å‘Šæ–‡ä»¶å¤¹å¤–éƒ¨ï¼ˆå¦‚_temp_imagesç›®å½•ï¼‰
                # ç›´æ¥ä½¿ç”¨å›¾ç‰‡æ–‡ä»¶å¤¹åç§°
                http_path = quote(f"{image_folder_name}/{image_filename}", safe='/')
            paths['http_url'] = f"http://localhost:8000/{http_path}"
        else:
            # å¦‚æœæ²¡æœ‰æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„ï¼Œä½¿ç”¨ç®€å•çš„ç›¸å¯¹è·¯å¾„
            http_path = quote(f"{image_folder_name}/{image_filename}", safe='/')
            paths['http_url'] = f"http://localhost:8000/{http_path}"
        
    except Exception as e:
        # å¦‚æœè·¯å¾„ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨åŸºæœ¬çš„ç›¸å¯¹è·¯å¾„
        paths['markdown'] = f"![]({image_folder_name}/{image_filename})"
        paths['relative'] = f"{image_folder_name}/{image_filename}"
        paths['file_url'] = f"file://{image_path}"
        paths['http_url'] = f"http://localhost:8000/{quote(paths['relative'], safe='/')}"
    
    return paths

def extract_metadata_from_filename(file_path):
    """
    ä»æ–‡ä»¶è·¯å¾„ä¸­æå–å…ƒæ•°æ®ä¿¡æ¯
    
    Args:
        file_path: æ–‡ä»¶è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
        "/path/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š_grouped.json"
    
    Returns:
        dict: åŒ…å«å…ƒæ•°æ®çš„å­—å…¸ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
        - stock_code: è‚¡ç¥¨ä»£ç 
        - company_name: å…¬å¸åç§°
        - report_year: æŠ¥å‘Šå¹´ä»½
        - report_title: æŠ¥å‘Šæ ‡é¢˜ï¼ˆå®Œæ•´ï¼‰
        - report_type: æŠ¥å‘Šç±»å‹ï¼ˆç»Ÿä¸€ä¸º"ESG_Report"ï¼‰
        - market: å¸‚åœºï¼ˆç»Ÿä¸€ä¸º"China"ï¼‰
        - original_filename: åŸå§‹æ–‡ä»¶å
    """
    # è·å–æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„å’Œæ‰©å±•åï¼‰
    filename = os.path.splitext(os.path.basename(file_path))[0]
    
    # ç§»é™¤ _grouped åç¼€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if filename.endswith('_grouped'):
        filename = filename[:-8]
    elif filename.endswith('_vlm'):
        filename = filename[:-4]
    
    # å®šä¹‰æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼æ¥è§£ææ–‡ä»¶å
    # æ”¯æŒä¸¤ç§æ ¼å¼:
    # æ ¼å¼1: è‚¡ç¥¨ä»£ç -å…¬å¸åç§°-å¹´ä»½å¹´åº¦æŠ¥å‘Šç±»å‹
    # æ ¼å¼2: è‚¡ç¥¨ä»£ç -å…¬å¸åç§°-å¹´ä»½å¹´æŠ¥å‘Šç±»å‹
    patterns = [
        r'^([^-]+)-([^-]+)-(\d{4})å¹´åº¦(.+)$',  # æœ‰"å¹´åº¦"çš„æ ¼å¼
        r'^([^-]+)-([^-]+)-(\d{4})å¹´(.+)$'      # æ²¡æœ‰"å¹´åº¦"çš„æ ¼å¼
    ]
    
    match = None
    has_year_degree = False
    
    for i, pattern in enumerate(patterns):
        match = re.match(pattern, filename)
        if match:
            has_year_degree = (i == 0)  # ç¬¬ä¸€ä¸ªæ¨¡å¼åŒ…å«"å¹´åº¦"
            break
    
    if match:
        stock_code = match.group(1).strip()
        company_name = match.group(2).strip()
        report_year = int(match.group(3))
        report_type = match.group(4).strip()
        
        # æ„å»ºå®Œæ•´çš„æŠ¥å‘Šæ ‡é¢˜
        if has_year_degree:
            report_title = f"{report_year}å¹´åº¦{report_type}"
        else:
            report_title = f"{report_year}å¹´{report_type}"
        
        return {
            "stock_code": stock_code,
            "company_name": company_name,
            "report_year": report_year,
            "report_title": report_title,
            "report_type": "ESG_Report",
            "market": "China",
            "original_filename": os.path.basename(file_path)
        }
    else:
        # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›é»˜è®¤å€¼
        return {
            "stock_code": "UNKNOWN",
            "company_name": "æœªçŸ¥å…¬å¸",
            "report_year": None,
            "report_title": "æœªçŸ¥æŠ¥å‘Š",
            "report_type": "ESG_Report",
            "market": "China",
            "original_filename": os.path.basename(file_path)
        }

def restore_and_group_by_page(input_path, output_path, image_folder_path):
    with open(input_path, 'r', encoding='utf-8') as f:
        blocks = json.load(f)

    # å…ˆæ‹†åˆ†èšç±»å—ï¼Œä¿ç•™data_typeåˆ†é…
    flat_blocks = []
    for block in blocks:
        if block.get('data_type', '').startswith('cluster'):
            data_indices = block['data_indices']
            data_list = block['data']
            # è§£ædata_typesä¸ºåˆ—è¡¨
            data_types = []
            if 'data_types' in block and block['data_types']:
                data_types = block['data_types']
            else:
                # cluster[text,image,text] è¿™ç§æ ¼å¼
                type_str = block['data_type'][len('cluster['):-1]
                data_types = [t.strip() for t in type_str.split(',')]
            
            # è·å–tableç›¸å…³çš„è·¯å¾„ä¿¡æ¯
            table_paths = block.get('table_markdown_urls', [])  # æ›´æ–°å­—æ®µå
            table_file_urls = block.get('table_file_urls', [])
            table_http_urls = block.get('table_http_urls', [])
            table_relative_paths = block.get('table_relative_paths', [])
            table_index = 0  # ç”¨äºè·Ÿè¸ªtableç±»å‹çš„ç´¢å¼•
            
            # è·å–imageç›¸å…³çš„è·¯å¾„ä¿¡æ¯
            image_paths = block.get('image_markdown_urls', [])  # æ›´æ–°å­—æ®µå
            image_file_urls = block.get('image_file_urls', [])
            image_http_urls = block.get('image_http_urls', [])
            image_relative_paths = block.get('image_relative_paths', [])
            
            # è¿‡æ»¤æ‰dataä¸ºnullçš„å…ƒç´ 
            valid_data = []
            valid_indices = []
            valid_types = []
            
            for i, (idx, data) in enumerate(zip(data_indices, data_list)):
                # è·³è¿‡nullæ•°æ®
                if data is None:
                    continue
                    
                valid_data.append(data)
                valid_indices.append(idx)
                dtype = data_types[i] if i < len(data_types) else 'text'
                valid_types.append(dtype)
            
            # ä½¿ç”¨è¿‡æ»¤åçš„æ•°æ®åˆ›å»ºå—
            image_index = 0  # ç”¨äºè·Ÿè¸ªå›¾ç‰‡è·¯å¾„æ•°ç»„çš„ç´¢å¼•
            table_index = 0  # ç”¨äºè·Ÿè¸ªè¡¨æ ¼è·¯å¾„æ•°ç»„çš„ç´¢å¼•
            
            for i, (idx, data) in enumerate(zip(valid_indices, valid_data)):
                page_idx, original_reading_order = idx
                dtype = valid_types[i]
                
                # é€‰æ‹© reading_order ç­–ç•¥ï¼š
                # æ–¹æ¡ˆ1ï¼šä¿æŒåŸå§‹ reading_orderï¼ˆä¿æŒä¸åŸæ–‡æ¡£çš„å¯¹åº”å…³ç³»ï¼‰
                reading_order = original_reading_order
                
                # æ–¹æ¡ˆ2ï¼šé‡æ–°åˆ†é…è¿ç»­çš„ reading_orderï¼ˆå¦‚æœéœ€è¦è¿ç»­æ€§ï¼Œå–æ¶ˆä¸‹é¢çš„æ³¨é‡Šï¼‰
                # reading_order = i + 1  # ä»1å¼€å§‹çš„è¿ç»­ç¼–å·
                
                block_dict = {
                    "h1": block.get("h1"),
                    "h2": block.get("h2"),
                    "h3": block.get("h3"),
                    "h4": block.get("h4"),
                    "data_type": dtype,
                    "data": data,
                    "reading_order": reading_order,
                    "page_idx": page_idx
                }
                
                # å¦‚æœæ˜¯å›¾ç‰‡ç±»å‹ï¼Œæ·»åŠ imageç›¸å…³è·¯å¾„å­—æ®µ
                if isinstance(dtype, str) and dtype.startswith('image'):
                    # ä½¿ç”¨å›¾ç‰‡ç´¢å¼•æ¥è·å–å¯¹åº”çš„è·¯å¾„ä¿¡æ¯
                    if image_index < len(image_paths):
                        block_dict["image_markdown_url"] = image_paths[image_index]
                    if image_index < len(image_file_urls):
                        block_dict["image_file_url"] = image_file_urls[image_index]
                    if image_index < len(image_relative_paths):
                        block_dict["image_relative_path"] = image_relative_paths[image_index]
                    if image_index < len(image_http_urls):
                        block_dict["image_http_url"] = image_http_urls[image_index]
                    image_index += 1  # å¤„ç†å®Œä¸€ä¸ªå›¾ç‰‡åï¼Œç´¢å¼•+1
                    
                # å¦‚æœæ˜¯è¡¨æ ¼ç±»å‹ï¼Œæ·»åŠ tableç›¸å…³è·¯å¾„å­—æ®µ
                elif isinstance(dtype, str) and dtype.startswith('table'):
                    # ä½¿ç”¨è¡¨æ ¼ç´¢å¼•æ¥è·å–å¯¹åº”çš„è·¯å¾„ä¿¡æ¯
                    if table_index < len(table_paths):
                        block_dict["table_markdown_url"] = table_paths[table_index]
                    if table_index < len(table_file_urls):
                        block_dict["table_file_url"] = table_file_urls[table_index]
                    if table_index < len(table_relative_paths):
                        block_dict["table_relative_path"] = table_relative_paths[table_index]
                    if table_index < len(table_http_urls):
                        block_dict["table_http_url"] = table_http_urls[table_index]
                    table_index += 1  # å¤„ç†å®Œä¸€ä¸ªè¡¨æ ¼åï¼Œç´¢å¼•+1
                    
                flat_blocks.append(block_dict)
        else:
            # å¤„ç†æ™®é€šå—ï¼Œç¡®ä¿å›¾ç‰‡å’Œè¡¨æ ¼å­—æ®µæ­£ç¡®ä¼ é€’
            if 'image_markdown_url' in block:
                # æ™®é€šå›¾ç‰‡å—å·²ç»æœ‰æ­£ç¡®çš„å­—æ®µåï¼Œä¸éœ€è¦ä¿®æ”¹
                pass
            if 'table_markdown_url' in block:
                # æ™®é€šè¡¨æ ¼å—å·²ç»æœ‰æ­£ç¡®çš„å­—æ®µåï¼Œä¸éœ€è¦ä¿®æ”¹
                pass
            flat_blocks.append(block)

    # æŒ‰ page_idx èšåˆ
    page_dict = defaultdict(list)
    for block in flat_blocks:
        page_dict[block['page_idx']].append(block)

    # åˆ é™¤æ¯ä¸ªå—ä¸­çš„ page_idx å­—æ®µ
    for page_blocks in page_dict.values():
        for block in page_blocks:
            block.pop('page_idx', None)

    # æŒ‰ page_idx æ’åºï¼Œcontent å†…æŒ‰ reading_order æ’åº
    result = []
    for page_idx in sorted(page_dict):
        content = sorted(page_dict[page_idx], key=lambda b: b['reading_order'])
        
        # æ„å»ºå¯¹åº”çš„å›¾ç‰‡è·¯å¾„ï¼ˆå¤šç§æ ¼å¼ï¼‰
        image_filename = f"{page_idx}.jpg"
        
        # ä½¿ç”¨è·¨å¹³å°è·¯å¾„ç”Ÿæˆå‡½æ•°ï¼Œä¼ é€’æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„
        report_folder_path = os.path.dirname(image_folder_path)
        paths = generate_cross_platform_paths(image_folder_path, image_filename, report_folder_path)
        
        result.append({
            "page_idx": page_idx,
            "page_markdown_url": paths['markdown'],  # Markdownæ ¼å¼çš„å›¾ç‰‡é“¾æ¥
            "page_file_url": paths['file_url'],  # ç»å¯¹è·¯å¾„file://é“¾æ¥ï¼ˆæœ¬æœºæœ‰æ•ˆï¼‰
            "page_relative_path": paths['relative'],  # ç³»ç»Ÿç›¸å¯¹è·¯å¾„
            "page_http_url": paths['http_url'],  # HTTPæœ¬åœ°æœåŠ¡å™¨é“¾æ¥
            "content": content
        })

    # æå–å…ƒæ•°æ®
    metadata = extract_metadata_from_filename(output_path)
    
    # æ„å»ºæœ€ç»ˆè¾“å‡ºç»“æ„ï¼Œå…ƒæ•°æ®åœ¨å‰
    final_output = {
        "metadata": metadata,
        "pages": result
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(final_output, f, ensure_ascii=False, indent=2)

def display_json_with_images(json_path, image_folder_path):
    """
    åœ¨Jupyterä¸­å¹¶æ’æ˜¾ç¤ºJSONå†…å®¹å’Œå¯¹åº”çš„å›¾ç‰‡
    """
    import json
    from IPython.display import HTML, Image, display
    import pandas as pd
    
    # è¯»å–JSONæ–‡ä»¶
    with open(json_path, 'r', encoding='utf-8') as f:
        json_data = json.load(f)
    
    # æ£€æŸ¥æ–°çš„JSONç»“æ„
    if "metadata" in json_data and "pages" in json_data:
        metadata = json_data["metadata"]
        data = json_data["pages"]
        
        # æ˜¾ç¤ºå…ƒæ•°æ®ä¿¡æ¯
        metadata_html = f"""
        <div style="background-color: #e6f3ff; padding: 15px; margin-bottom: 20px; border-radius: 8px; border-left: 4px solid #007acc;">
            <h3 style="margin-top: 0; color: #007acc;">ğŸ“Š æŠ¥å‘Šå…ƒæ•°æ®</h3>
            <table style="width: 100%; border-collapse: collapse;">
                <tr><td style="font-weight: bold; padding: 5px;">è‚¡ç¥¨ä»£ç :</td><td style="padding: 5px;">{metadata.get('stock_code', 'N/A')}</td></tr>
                <tr><td style="font-weight: bold; padding: 5px;">å…¬å¸åç§°:</td><td style="padding: 5px;">{metadata.get('company_name', 'N/A')}</td></tr>
                <tr><td style="font-weight: bold; padding: 5px;">æŠ¥å‘Šå¹´ä»½:</td><td style="padding: 5px;">{metadata.get('report_year', 'N/A')}</td></tr>
                <tr><td style="font-weight: bold; padding: 5px;">æŠ¥å‘Šæ ‡é¢˜:</td><td style="padding: 5px;">{metadata.get('report_title', 'N/A')}</td></tr>
                <tr><td style="font-weight: bold; padding: 5px;">æŠ¥å‘Šç±»å‹:</td><td style="padding: 5px;">{metadata.get('report_type', 'N/A')}</td></tr>
                <tr><td style="font-weight: bold; padding: 5px;">å¸‚åœº:</td><td style="padding: 5px;">{metadata.get('market', 'N/A')}</td></tr>
            </table>
        </div>
        """
        display(HTML(metadata_html))
    else:
        # å…¼å®¹æ—§æ ¼å¼
        data = json_data
    
    # åˆ›å»ºHTMLè¡¨æ ¼æ˜¾ç¤º
    html_content = """
    <style>
    .content-table {
        width: 100%;
        border-collapse: collapse;
        margin-bottom: 20px;
    }
    .content-table th {
        background-color: #f2f2f2;
        padding: 12px;
        text-align: center;
        font-weight: bold;
        border: 1px solid #ddd;
    }
    .content-table td {
        padding: 10px;
        border: 1px solid #ddd;
        vertical-align: top;
    }
    .content-cell {
        max-height: 500px;
        overflow-y: auto;
        background-color: #f9f9f9;
    }
    .image-cell {
        text-align: center;
        background-color: #f9f9f9;
    }
    .page-header {
        background-color: #e6f3ff;
        padding: 8px;
        margin-bottom: 10px;
        border-radius: 5px;
        font-weight: bold;
    }
    .content-cell pre {
        margin: 0;
        white-space: pre-wrap;
        font-size: 12px;
        text-align: left;
    }
    img.page-img {
        max-width: 100%;
        max-height: 400px;
        border: 1px solid #ddd;
        border-radius: 5px;
        cursor: zoom-in;
        transition: box-shadow 0.2s;
    }
    .img-modal {
        display: none;
        position: fixed;
        z-index: 9999;
        left: 0; top: 0; width: 100vw; height: 100vh;
        background: rgba(0,0,0,0.7);
        justify-content: center;
        align-items: center;
    }
    .img-modal img {
        max-width: 90vw;
        max-height: 90vh;
        box-shadow: 0 0 20px #fff;
        border-radius: 8px;
        background: #fff;
    }
    .img-modal.active { display: flex; }
    </style>
    """
    
    for item in data:
        page_idx = item['page_idx']
        content = json.dumps(item['content'], ensure_ascii=False, indent=2)
        page_path = item.get('page_file_url', item.get('page_relative_path', ''))
        
        html_content += f"""
        <div class="page-header">ğŸ“„ Page {page_idx}</div>
        <table class="content-table">
        <tr>
            <th style="width:50%;">é¡µé¢å†…å®¹ (JSONæ ¼å¼)</th>
            <th style="width:50%;">é¡µé¢å›¾ç‰‡</th>
        </tr>
        <tr>
            <td class="content-cell">
                <pre>{content}</pre>
            </td>
            <td class="image-cell">
                <img class='page-img' src="{page_path}" alt="Page {page_idx}" onclick="showImgModal(this)">
            </td>
        </tr>
        </table>
        <hr style="margin: 30px 0;">
        """
    
    # æ·»åŠ å¼¹çª—å’ŒJS
    html_content += """
    <script>
    function showImgModal(img) {
        var modal = document.getElementById('img-modal');
        var modalImg = document.getElementById('img-modal-img');
        modalImg.src = img.src;
        modal.classList.add('active');
    }
    function hideImgModal() {
        var modal = document.getElementById('img-modal');
        modal.classList.remove('active');
    }
    </script>
    <div id="img-modal" class="img-modal" onclick="hideImgModal()">
        <img id="img-modal-img" src="" />
    </div>
    """
    
    display(HTML(html_content))

def test_metadata_extraction():
    """æµ‹è¯•å…ƒæ•°æ®æå–åŠŸèƒ½"""
    test_cases = [
        "300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š_grouped.json",
        "000001.SZ-å¹³å®‰é“¶è¡Œ-2023å¹´åº¦å¯æŒç»­å‘å±•æŠ¥å‘Š_vlm.json",
        "600036.SH-æ‹›å•†é“¶è¡Œ-2022å¹´åº¦ESGæŠ¥å‘Š.json",
        "BABA.US-é˜¿é‡Œå·´å·´-2024å¹´åº¦ç¯å¢ƒæŠ¥å‘Š_grouped.json",
        "600720.SH-ä¸­äº¤è®¾è®¡-2024å¹´ç¯å¢ƒã€ç¤¾ä¼šä¸æ²»ç†æŠ¥å‘Š_grouped.json",  # æ–°å¢ï¼šæ²¡æœ‰"å¹´åº¦"çš„æ ¼å¼
        "601677.SH-æ˜æ³°é“ä¸š-2024å¹´åº¦ESGæŠ¥å‘Š_grouped.json"  # æ–°å¢ï¼šæœ‰"å¹´åº¦"çš„æ ¼å¼
    ]
    
    print("ğŸ§ª å…ƒæ•°æ®æå–æµ‹è¯•:")
    print("=" * 60)
    
    for filename in test_cases:
        print(f"\nğŸ“„ æ–‡ä»¶å: {filename}")
        metadata = extract_metadata_from_filename(filename)
        for key, value in metadata.items():
            print(f"   {key}: {value}")
        print("-" * 40)

def process_esg_report(report_folder_path, report_name=None):
    """
    å¤„ç†ESGæŠ¥å‘Šçš„é€šç”¨å‡½æ•°
    
    Args:
        report_folder_path: æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„
        report_name: æŠ¥å‘Šåç§°ï¼ˆå¯é€‰ï¼Œä»æ–‡ä»¶å¤¹åç§°è‡ªåŠ¨æ¨æ–­ï¼‰
    """
    if report_name is None:
        report_name = os.path.basename(report_folder_path)
    
    # æ„å»ºæ–‡ä»¶è·¯å¾„
    input_path = os.path.join(report_folder_path, f"{report_name}_vlm.json")
    output_path = os.path.join(report_folder_path, f"{report_name}_grouped.json")
    image_folder_path = os.path.join(report_folder_path, f"{report_name}_pages")
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(input_path):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return False
    
    if not os.path.exists(image_folder_path):
        print(f"âŒ å›¾ç‰‡æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {image_folder_path}")
        return False
    
    print(f"ğŸš€ å¼€å§‹å¤„ç†: {os.path.basename(input_path)}")
    print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_path}")
    print(f"ğŸ“ è¾“å‡ºæ–‡ä»¶: {output_path}")
    print(f"ğŸ“ å›¾ç‰‡æ–‡ä»¶å¤¹: {image_folder_path}")
    
    try:
        restore_and_group_by_page(input_path, output_path, image_folder_path)
        print(f"âœ… å¤„ç†å®Œæˆ: {os.path.basename(output_path)}")
        
        # æ˜¾ç¤ºæå–çš„å…ƒæ•°æ®
        with open(output_path, 'r', encoding='utf-8') as f:
            result = json.load(f)
            if "metadata" in result:
                print(f"\nğŸ“Š æå–çš„å…ƒæ•°æ®:")
                for key, value in result["metadata"].items():
                    print(f"   {key}: {value}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    # æµ‹è¯•å…ƒæ•°æ®æå–
    test_metadata_extraction()
    
    # é…ç½®åŒºåŸŸ - ä¿®æ”¹è¿™é‡Œçš„è·¯å¾„æ¥å¤„ç†ä¸åŒçš„æŠ¥å‘Š
    # ================================================================
    
    # è®¾ç½®è¦å¤„ç†çš„æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå–æ¶ˆæ³¨é‡Šå…¶ä¸­ä¸€è¡Œæ¥è¿è¡Œï¼‰
    # report_folder = None  # é»˜è®¤ä¸å¤„ç†ä»»ä½•æŠ¥å‘Š
    
    # ç¤ºä¾‹1: å¤„ç†å¯Œç¥¥è¯ä¸šæŠ¥å‘Š
    # report_folder = "/Users/liucun/Desktop/report_analysis/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š"
    
    # ç¤ºä¾‹2: å¤„ç†å¥å¸†ç”Ÿç‰©æŠ¥å‘Š
    report_folder = "/Users/liucun/Desktop/yiyao_fuxaing/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š"
    # ç¤ºä¾‹3: å¤„ç†å…´é½çœ¼è¯æŠ¥å‘Š
    # report_folder = "/Users/liucun/Desktop/report_analysis/300573.SZ-å…´é½çœ¼è¯-2024å¹´åº¦ç¯å¢ƒ,ç¤¾ä¼šä¸æ²»ç†(ESG)æŠ¥å‘Š"
    
    # ================================================================
    
    if report_folder is not None:
        success = process_esg_report(report_folder)
        if success:
            print(f"\nğŸ‰ æŠ¥å‘Šå¤„ç†æˆåŠŸï¼")
        else:
            print(f"\nâŒ æŠ¥å‘Šå¤„ç†å¤±è´¥ï¼")
    else:
        print("ğŸ’¡ è¯·åœ¨é…ç½®åŒºåŸŸæŒ‡å®šè¦å¤„ç†çš„æŠ¥å‘Šæ–‡ä»¶å¤¹è·¯å¾„")
        print("ğŸ’¡ å–æ¶ˆæ³¨é‡Šå¹¶è®¾ç½® report_folder = \"...\" æ¥è¿è¡Œå¤„ç†")

# ä½¿ç”¨ç¤ºä¾‹ï¼ˆåœ¨Jupyterä¸­è¿è¡Œï¼‰:
# display_json_with_images(
#     "/Users/liucun/Desktop/report_analysis/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š_grouped.json",
#     "/Users/liucun/Desktop/report_analysis/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š/300497.SZ-å¯Œç¥¥è¯ä¸š-2024å¹´åº¦ç¯å¢ƒã€ç¤¾ä¼šåŠå…¬å¸æ²»ç†(ESG)æŠ¥å‘Š_pages"
# ) 